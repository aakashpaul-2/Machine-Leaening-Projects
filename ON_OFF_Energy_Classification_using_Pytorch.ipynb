{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ON/OFF Energy Classification using Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOU9SJVpG2ILJBH3ws8h+Wq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakashpaul-2/Machine-Learning-Projects/blob/main/ON_OFF_Energy_Classification_using_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL3Banr0o4VD"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s_15dEQwyRF",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "35c08a4d-a2d5-444d-ac50-cccb0dc7a524"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9d19b021-6569-4529-8ad6-8707c611a120\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9d19b021-6569-4529-8ad6-8707c611a120\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Q3-data.csv to Q3-data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeeWLrcJw4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "61de03c7-ffb6-4bac-f32f-c731aa9c9e27"
      },
      "source": [
        "df = pd.read_csv(\"Q3-data.csv\")\n",
        "df_house_1 = df.loc[df[\"House\"] == 1]\n",
        "           \n",
        "df_house_1.loc[df_house_1[\"TV\"]  > 15, \"ON/OFF\"] = 1\n",
        "df_house_1.loc[df_house_1[\"TV\"]  <= 15, \"ON/OFF\"] = 0\n",
        "\n",
        "X_h1 = df_house_1.iloc[:,[1,3]]\n",
        "y_h1 = (df_house_1.iloc[:,2])\n",
        "\n",
        "# Split data set: House 2\n",
        "\n",
        "df_house_2 = df.loc[df[\"House\"] == 2]\n",
        "df_house_2.loc[df_house_2[\"TV\"]  > 30, \"ON/OFF\"] = 1\n",
        "df_house_2.loc[df_house_2[\"TV\"]  <= 30, \"ON/OFF\"] = 0\n",
        "\n",
        "X_h2 = df_house_2.iloc[:,[1,3]]\n",
        "y_h2 = (df_house_2.iloc[:,2])\n",
        "\n",
        "# Split data set: House 3\n",
        "\n",
        "df_house_3 = df.loc[df[\"House\"] == 3]\n",
        "df_house_3.loc[df_house_3[\"TV\"]  > 30, \"ON/OFF\"] = 1\n",
        "df_house_3.loc[df_house_3[\"TV\"]  <= 30, \"ON/OFF\"] = 0\n",
        "\n",
        "X_h3 = df_house_3.iloc[:,[1,3]]\n",
        "y_h3 = df_house_3.iloc[:,2]\n",
        "\n",
        "\n",
        "\n",
        "# Data for Training Set\n",
        "X_train = pd.concat([X_h1,X_h3])\n",
        "X_train = X_train.values\n",
        "y_train = pd.concat([y_h1, y_h3])\n",
        "y_train = y_train.values.astype(np.float64)\n",
        "\n",
        "# Test Set\n",
        "X_test = X_h2.values\n",
        "y_test = y_h2.values.astype(np.float64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[key] = _infer_fill_value(value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:850: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(new_indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNWHVGtrw8MZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7af8e1f-e42b-41d3-fe78-3e3c4a3167c0"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scX = MinMaxScaler(feature_range = (0,1))\n",
        "scY = MinMaxScaler(feature_range = (0,1))\n",
        "X_train = scX.fit_transform(X = X_train)\n",
        "X_test = scX.fit_transform(X = X_test)\n",
        "\n",
        "y_train = np.array(y_train).reshape(-1,1)\n",
        "y_test = np.array(y_test).reshape(-1,1)\n",
        "y_train = scY.fit_transform(X = y_train)\n",
        "y_test = scY.fit_transform(X = y_test)\n",
        "\n",
        "\n",
        "print(\"X.shape\", X_train.shape, \"Y.shape\", y_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.shape (2880, 2) Y.shape (2880, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbFp-hSj0M-w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6d5468f-7b43-4ea9-ea51-fcbe80b259b1"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t0VE9Nf0s1_"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(2, 128),nn.ReLU(), nn.Dropout(0.25), nn.Linear(128, 256), nn.ReLU(), nn.Dropout(0.2), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, 1))\n",
        "model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KmRbF3e0tgv"
      },
      "source": [
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkjUbd4P0-jt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01291bb6-89f7-4e79-e928-ec2e40f5c5d0"
      },
      "source": [
        "def full_gd(model,criterion,optimizer,X_train,y_train,X_test,y_test,epochs=1500):\n",
        "    train_losses = np.zeros(epochs)\n",
        "    test_losses = np.zeros(epochs)\n",
        "    \n",
        "    for it in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs,y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses[it] = loss.item()\n",
        "        \n",
        "        test_outputs = model(X_test)\n",
        "        test_loss = criterion(test_outputs,y_test)\n",
        "        test_losses[it] = test_loss.item()\n",
        "        \n",
        "        print(\"Epoch: {}, Train Loss: {}, Test Loss: {}\".format(it,loss.item(),test_loss.item()))\n",
        "        \n",
        "    return train_losses, test_losses       \n",
        "\n",
        "train_losses, test_losses = full_gd(model,criterion,optimizer,X_train,y_train,X_test,y_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Train Loss: 0.11096994578838348, Test Loss: 0.23715320229530334\n",
            "Epoch: 1, Train Loss: 0.06611469388008118, Test Loss: 0.20503968000411987\n",
            "Epoch: 2, Train Loss: 0.06018497794866562, Test Loss: 0.20161527395248413\n",
            "Epoch: 3, Train Loss: 0.07051193714141846, Test Loss: 0.20165041089057922\n",
            "Epoch: 4, Train Loss: 0.06670303642749786, Test Loss: 0.20287317037582397\n",
            "Epoch: 5, Train Loss: 0.06009722873568535, Test Loss: 0.20824114978313446\n",
            "Epoch: 6, Train Loss: 0.05724509060382843, Test Loss: 0.21481256186962128\n",
            "Epoch: 7, Train Loss: 0.057406459003686905, Test Loss: 0.22060810029506683\n",
            "Epoch: 8, Train Loss: 0.058681607246398926, Test Loss: 0.22382639348506927\n",
            "Epoch: 9, Train Loss: 0.05960845202207565, Test Loss: 0.22405767440795898\n",
            "Epoch: 10, Train Loss: 0.06029186770319939, Test Loss: 0.224107027053833\n",
            "Epoch: 11, Train Loss: 0.05933656916022301, Test Loss: 0.21956798434257507\n",
            "Epoch: 12, Train Loss: 0.05816364288330078, Test Loss: 0.21733053028583527\n",
            "Epoch: 13, Train Loss: 0.05693558603525162, Test Loss: 0.21254141628742218\n",
            "Epoch: 14, Train Loss: 0.05586918815970421, Test Loss: 0.2076183408498764\n",
            "Epoch: 15, Train Loss: 0.055335331708192825, Test Loss: 0.20564915239810944\n",
            "Epoch: 16, Train Loss: 0.05539451166987419, Test Loss: 0.20285053551197052\n",
            "Epoch: 17, Train Loss: 0.05575136840343475, Test Loss: 0.2025250941514969\n",
            "Epoch: 18, Train Loss: 0.05653166398406029, Test Loss: 0.20279505848884583\n",
            "Epoch: 19, Train Loss: 0.055878896266222, Test Loss: 0.2035759836435318\n",
            "Epoch: 20, Train Loss: 0.05513305962085724, Test Loss: 0.20434346795082092\n",
            "Epoch: 21, Train Loss: 0.05471336096525192, Test Loss: 0.20740963518619537\n",
            "Epoch: 22, Train Loss: 0.05404423922300339, Test Loss: 0.2080061435699463\n",
            "Epoch: 23, Train Loss: 0.05380462110042572, Test Loss: 0.21058955788612366\n",
            "Epoch: 24, Train Loss: 0.053855594247579575, Test Loss: 0.21216706931591034\n",
            "Epoch: 25, Train Loss: 0.0537724494934082, Test Loss: 0.21359576284885406\n",
            "Epoch: 26, Train Loss: 0.05369160696864128, Test Loss: 0.21192623674869537\n",
            "Epoch: 27, Train Loss: 0.05329859256744385, Test Loss: 0.2114419788122177\n",
            "Epoch: 28, Train Loss: 0.05298827588558197, Test Loss: 0.21062538027763367\n",
            "Epoch: 29, Train Loss: 0.05232883244752884, Test Loss: 0.20891565084457397\n",
            "Epoch: 30, Train Loss: 0.0524786151945591, Test Loss: 0.20704369246959686\n",
            "Epoch: 31, Train Loss: 0.05252664536237717, Test Loss: 0.20641595125198364\n",
            "Epoch: 32, Train Loss: 0.05251815542578697, Test Loss: 0.20845015347003937\n",
            "Epoch: 33, Train Loss: 0.05249183997511864, Test Loss: 0.20625780522823334\n",
            "Epoch: 34, Train Loss: 0.05227959156036377, Test Loss: 0.20623406767845154\n",
            "Epoch: 35, Train Loss: 0.0516519621014595, Test Loss: 0.20653584599494934\n",
            "Epoch: 36, Train Loss: 0.05164741352200508, Test Loss: 0.20833896100521088\n",
            "Epoch: 37, Train Loss: 0.05139059200882912, Test Loss: 0.20938093960285187\n",
            "Epoch: 38, Train Loss: 0.051309458911418915, Test Loss: 0.20826251804828644\n",
            "Epoch: 39, Train Loss: 0.051172588020563126, Test Loss: 0.20505167543888092\n",
            "Epoch: 40, Train Loss: 0.0505969375371933, Test Loss: 0.20440854132175446\n",
            "Epoch: 41, Train Loss: 0.04976795241236687, Test Loss: 0.20089282095432281\n",
            "Epoch: 42, Train Loss: 0.04997203126549721, Test Loss: 0.19933688640594482\n",
            "Epoch: 43, Train Loss: 0.049201272428035736, Test Loss: 0.20026014745235443\n",
            "Epoch: 44, Train Loss: 0.049800340086221695, Test Loss: 0.19910089671611786\n",
            "Epoch: 45, Train Loss: 0.04943495988845825, Test Loss: 0.20092982053756714\n",
            "Epoch: 46, Train Loss: 0.04895591363310814, Test Loss: 0.19992120563983917\n",
            "Epoch: 47, Train Loss: 0.04891769587993622, Test Loss: 0.197478786110878\n",
            "Epoch: 48, Train Loss: 0.04804700240492821, Test Loss: 0.19923155009746552\n",
            "Epoch: 49, Train Loss: 0.048699814826250076, Test Loss: 0.19631561636924744\n",
            "Epoch: 50, Train Loss: 0.04794697463512421, Test Loss: 0.1922914832830429\n",
            "Epoch: 51, Train Loss: 0.04801319167017937, Test Loss: 0.19166319072246552\n",
            "Epoch: 52, Train Loss: 0.04810990393161774, Test Loss: 0.1899583637714386\n",
            "Epoch: 53, Train Loss: 0.04787367954850197, Test Loss: 0.19236980378627777\n",
            "Epoch: 54, Train Loss: 0.047866642475128174, Test Loss: 0.19147835671901703\n",
            "Epoch: 55, Train Loss: 0.04732950031757355, Test Loss: 0.19320367276668549\n",
            "Epoch: 56, Train Loss: 0.04691729694604874, Test Loss: 0.19031186401844025\n",
            "Epoch: 57, Train Loss: 0.046928469091653824, Test Loss: 0.18724225461483002\n",
            "Epoch: 58, Train Loss: 0.04776083305478096, Test Loss: 0.18828445672988892\n",
            "Epoch: 59, Train Loss: 0.047320686280727386, Test Loss: 0.18824218213558197\n",
            "Epoch: 60, Train Loss: 0.04678735136985779, Test Loss: 0.1881093829870224\n",
            "Epoch: 61, Train Loss: 0.04698570817708969, Test Loss: 0.1883610188961029\n",
            "Epoch: 62, Train Loss: 0.04701973870396614, Test Loss: 0.18879644572734833\n",
            "Epoch: 63, Train Loss: 0.046376749873161316, Test Loss: 0.18535739183425903\n",
            "Epoch: 64, Train Loss: 0.04664382338523865, Test Loss: 0.1875070184469223\n",
            "Epoch: 65, Train Loss: 0.046186503022909164, Test Loss: 0.18482732772827148\n",
            "Epoch: 66, Train Loss: 0.04615562781691551, Test Loss: 0.18669934570789337\n",
            "Epoch: 67, Train Loss: 0.04571731388568878, Test Loss: 0.1845797747373581\n",
            "Epoch: 68, Train Loss: 0.04542410373687744, Test Loss: 0.18691575527191162\n",
            "Epoch: 69, Train Loss: 0.04582812264561653, Test Loss: 0.1858161985874176\n",
            "Epoch: 70, Train Loss: 0.045690249651670456, Test Loss: 0.18349435925483704\n",
            "Epoch: 71, Train Loss: 0.04572527855634689, Test Loss: 0.18566983938217163\n",
            "Epoch: 72, Train Loss: 0.04558895155787468, Test Loss: 0.18555213510990143\n",
            "Epoch: 73, Train Loss: 0.044895123690366745, Test Loss: 0.18394246697425842\n",
            "Epoch: 74, Train Loss: 0.04575527459383011, Test Loss: 0.18378224968910217\n",
            "Epoch: 75, Train Loss: 0.04555998370051384, Test Loss: 0.18435969948768616\n",
            "Epoch: 76, Train Loss: 0.044990651309490204, Test Loss: 0.1836487054824829\n",
            "Epoch: 77, Train Loss: 0.04565257206559181, Test Loss: 0.18239425122737885\n",
            "Epoch: 78, Train Loss: 0.04520531743764877, Test Loss: 0.18422408401966095\n",
            "Epoch: 79, Train Loss: 0.045111678540706635, Test Loss: 0.18432316184043884\n",
            "Epoch: 80, Train Loss: 0.04505063220858574, Test Loss: 0.1842462569475174\n",
            "Epoch: 81, Train Loss: 0.04532315954566002, Test Loss: 0.18249042332172394\n",
            "Epoch: 82, Train Loss: 0.04522422328591347, Test Loss: 0.18307974934577942\n",
            "Epoch: 83, Train Loss: 0.04486773535609245, Test Loss: 0.18184293806552887\n",
            "Epoch: 84, Train Loss: 0.04480356350541115, Test Loss: 0.1840866059064865\n",
            "Epoch: 85, Train Loss: 0.04450475051999092, Test Loss: 0.18288765847682953\n",
            "Epoch: 86, Train Loss: 0.044377654790878296, Test Loss: 0.18376539647579193\n",
            "Epoch: 87, Train Loss: 0.04533788934350014, Test Loss: 0.18189865350723267\n",
            "Epoch: 88, Train Loss: 0.044413041323423386, Test Loss: 0.18313275277614594\n",
            "Epoch: 89, Train Loss: 0.0445052795112133, Test Loss: 0.18182212114334106\n",
            "Epoch: 90, Train Loss: 0.04474726319313049, Test Loss: 0.18231400847434998\n",
            "Epoch: 91, Train Loss: 0.04457198828458786, Test Loss: 0.1828528195619583\n",
            "Epoch: 92, Train Loss: 0.04429996386170387, Test Loss: 0.17992058396339417\n",
            "Epoch: 93, Train Loss: 0.045262232422828674, Test Loss: 0.18159383535385132\n",
            "Epoch: 94, Train Loss: 0.04437629133462906, Test Loss: 0.18132384121418\n",
            "Epoch: 95, Train Loss: 0.04375731945037842, Test Loss: 0.17941956222057343\n",
            "Epoch: 96, Train Loss: 0.04499806836247444, Test Loss: 0.18143156170845032\n",
            "Epoch: 97, Train Loss: 0.04396878555417061, Test Loss: 0.1816638559103012\n",
            "Epoch: 98, Train Loss: 0.044348668307065964, Test Loss: 0.18009808659553528\n",
            "Epoch: 99, Train Loss: 0.04520097374916077, Test Loss: 0.17875419557094574\n",
            "Epoch: 100, Train Loss: 0.04407161846756935, Test Loss: 0.17976002395153046\n",
            "Epoch: 101, Train Loss: 0.044593315571546555, Test Loss: 0.18139426410198212\n",
            "Epoch: 102, Train Loss: 0.0441136471927166, Test Loss: 0.17851227521896362\n",
            "Epoch: 103, Train Loss: 0.043934840708971024, Test Loss: 0.17885585129261017\n",
            "Epoch: 104, Train Loss: 0.04395115748047829, Test Loss: 0.1757931411266327\n",
            "Epoch: 105, Train Loss: 0.04430065304040909, Test Loss: 0.17787522077560425\n",
            "Epoch: 106, Train Loss: 0.04386276751756668, Test Loss: 0.178964301943779\n",
            "Epoch: 107, Train Loss: 0.0435979999601841, Test Loss: 0.1785924881696701\n",
            "Epoch: 108, Train Loss: 0.04388013109564781, Test Loss: 0.18052029609680176\n",
            "Epoch: 109, Train Loss: 0.04413892701268196, Test Loss: 0.17794862389564514\n",
            "Epoch: 110, Train Loss: 0.044765833765268326, Test Loss: 0.17901335656642914\n",
            "Epoch: 111, Train Loss: 0.04371841251850128, Test Loss: 0.1805223673582077\n",
            "Epoch: 112, Train Loss: 0.04465482011437416, Test Loss: 0.17659704387187958\n",
            "Epoch: 113, Train Loss: 0.04365707188844681, Test Loss: 0.17829401791095734\n",
            "Epoch: 114, Train Loss: 0.04335111007094383, Test Loss: 0.17707973718643188\n",
            "Epoch: 115, Train Loss: 0.0435384102165699, Test Loss: 0.1778692901134491\n",
            "Epoch: 116, Train Loss: 0.04382573440670967, Test Loss: 0.17826364934444427\n",
            "Epoch: 117, Train Loss: 0.044086143374443054, Test Loss: 0.1774384081363678\n",
            "Epoch: 118, Train Loss: 0.044080134481191635, Test Loss: 0.17835880815982819\n",
            "Epoch: 119, Train Loss: 0.04324762523174286, Test Loss: 0.17801980674266815\n",
            "Epoch: 120, Train Loss: 0.04399151727557182, Test Loss: 0.17601743340492249\n",
            "Epoch: 121, Train Loss: 0.04391726478934288, Test Loss: 0.17757990956306458\n",
            "Epoch: 122, Train Loss: 0.04287175461649895, Test Loss: 0.1776336431503296\n",
            "Epoch: 123, Train Loss: 0.04423035681247711, Test Loss: 0.17689040303230286\n",
            "Epoch: 124, Train Loss: 0.043686460703611374, Test Loss: 0.17589400708675385\n",
            "Epoch: 125, Train Loss: 0.04349566623568535, Test Loss: 0.17511077225208282\n",
            "Epoch: 126, Train Loss: 0.043594229966402054, Test Loss: 0.17683428525924683\n",
            "Epoch: 127, Train Loss: 0.04355057328939438, Test Loss: 0.1761579066514969\n",
            "Epoch: 128, Train Loss: 0.043317608535289764, Test Loss: 0.1754906177520752\n",
            "Epoch: 129, Train Loss: 0.0435902439057827, Test Loss: 0.17493346333503723\n",
            "Epoch: 130, Train Loss: 0.043000221252441406, Test Loss: 0.17303773760795593\n",
            "Epoch: 131, Train Loss: 0.04346974194049835, Test Loss: 0.1741981953382492\n",
            "Epoch: 132, Train Loss: 0.04344650357961655, Test Loss: 0.17529568076133728\n",
            "Epoch: 133, Train Loss: 0.04355727136135101, Test Loss: 0.17629443109035492\n",
            "Epoch: 134, Train Loss: 0.04395214840769768, Test Loss: 0.1728602647781372\n",
            "Epoch: 135, Train Loss: 0.04284285008907318, Test Loss: 0.17388029396533966\n",
            "Epoch: 136, Train Loss: 0.04330508038401604, Test Loss: 0.17382949590682983\n",
            "Epoch: 137, Train Loss: 0.043371669948101044, Test Loss: 0.17385201156139374\n",
            "Epoch: 138, Train Loss: 0.04274085536599159, Test Loss: 0.17383714020252228\n",
            "Epoch: 139, Train Loss: 0.042831115424633026, Test Loss: 0.17239408195018768\n",
            "Epoch: 140, Train Loss: 0.04320487007498741, Test Loss: 0.1738288253545761\n",
            "Epoch: 141, Train Loss: 0.042915526777505875, Test Loss: 0.17424118518829346\n",
            "Epoch: 142, Train Loss: 0.043444905430078506, Test Loss: 0.17307919263839722\n",
            "Epoch: 143, Train Loss: 0.043283797800540924, Test Loss: 0.17136767506599426\n",
            "Epoch: 144, Train Loss: 0.04293205216526985, Test Loss: 0.17181514203548431\n",
            "Epoch: 145, Train Loss: 0.043550245463848114, Test Loss: 0.17202407121658325\n",
            "Epoch: 146, Train Loss: 0.042939212173223495, Test Loss: 0.17392303049564362\n",
            "Epoch: 147, Train Loss: 0.04280005022883415, Test Loss: 0.17129790782928467\n",
            "Epoch: 148, Train Loss: 0.04314045608043671, Test Loss: 0.1660977303981781\n",
            "Epoch: 149, Train Loss: 0.042739592492580414, Test Loss: 0.16952121257781982\n",
            "Epoch: 150, Train Loss: 0.04276658967137337, Test Loss: 0.1745591163635254\n",
            "Epoch: 151, Train Loss: 0.043141331523656845, Test Loss: 0.17153504490852356\n",
            "Epoch: 152, Train Loss: 0.0434408076107502, Test Loss: 0.17110340297222137\n",
            "Epoch: 153, Train Loss: 0.04291652515530586, Test Loss: 0.17132192850112915\n",
            "Epoch: 154, Train Loss: 0.04284532368183136, Test Loss: 0.17043109238147736\n",
            "Epoch: 155, Train Loss: 0.04311654716730118, Test Loss: 0.17234434187412262\n",
            "Epoch: 156, Train Loss: 0.04283931851387024, Test Loss: 0.17187939584255219\n",
            "Epoch: 157, Train Loss: 0.043205901980400085, Test Loss: 0.17140737175941467\n",
            "Epoch: 158, Train Loss: 0.04260892793536186, Test Loss: 0.17055478692054749\n",
            "Epoch: 159, Train Loss: 0.04291193187236786, Test Loss: 0.16890940070152283\n",
            "Epoch: 160, Train Loss: 0.04304296895861626, Test Loss: 0.16875697672367096\n",
            "Epoch: 161, Train Loss: 0.04228445142507553, Test Loss: 0.16911950707435608\n",
            "Epoch: 162, Train Loss: 0.043023623526096344, Test Loss: 0.17001673579216003\n",
            "Epoch: 163, Train Loss: 0.04290490224957466, Test Loss: 0.16907335817813873\n",
            "Epoch: 164, Train Loss: 0.042973875999450684, Test Loss: 0.16811539232730865\n",
            "Epoch: 165, Train Loss: 0.04251626878976822, Test Loss: 0.16909381747245789\n",
            "Epoch: 166, Train Loss: 0.042488161474466324, Test Loss: 0.16971638798713684\n",
            "Epoch: 167, Train Loss: 0.042264267802238464, Test Loss: 0.1702008992433548\n",
            "Epoch: 168, Train Loss: 0.04248626530170441, Test Loss: 0.1678035408258438\n",
            "Epoch: 169, Train Loss: 0.042550232261419296, Test Loss: 0.16687104105949402\n",
            "Epoch: 170, Train Loss: 0.04296312853693962, Test Loss: 0.16725978255271912\n",
            "Epoch: 171, Train Loss: 0.04263727366924286, Test Loss: 0.166953906416893\n",
            "Epoch: 172, Train Loss: 0.04265275225043297, Test Loss: 0.16722974181175232\n",
            "Epoch: 173, Train Loss: 0.04214629530906677, Test Loss: 0.16885001957416534\n",
            "Epoch: 174, Train Loss: 0.042320024222135544, Test Loss: 0.16643016040325165\n",
            "Epoch: 175, Train Loss: 0.04237306863069534, Test Loss: 0.16752660274505615\n",
            "Epoch: 176, Train Loss: 0.04187580198049545, Test Loss: 0.1667189598083496\n",
            "Epoch: 177, Train Loss: 0.0421900600194931, Test Loss: 0.17006056010723114\n",
            "Epoch: 178, Train Loss: 0.04255087301135063, Test Loss: 0.16650080680847168\n",
            "Epoch: 179, Train Loss: 0.04239368066191673, Test Loss: 0.16591504216194153\n",
            "Epoch: 180, Train Loss: 0.04205118864774704, Test Loss: 0.16510306298732758\n",
            "Epoch: 181, Train Loss: 0.04260776937007904, Test Loss: 0.16554954648017883\n",
            "Epoch: 182, Train Loss: 0.042334314435720444, Test Loss: 0.16580335795879364\n",
            "Epoch: 183, Train Loss: 0.04212705418467522, Test Loss: 0.16794490814208984\n",
            "Epoch: 184, Train Loss: 0.04262099787592888, Test Loss: 0.1637817919254303\n",
            "Epoch: 185, Train Loss: 0.04292118921875954, Test Loss: 0.16439127922058105\n",
            "Epoch: 186, Train Loss: 0.04224977269768715, Test Loss: 0.16618284583091736\n",
            "Epoch: 187, Train Loss: 0.041761063039302826, Test Loss: 0.16867710649967194\n",
            "Epoch: 188, Train Loss: 0.042193952947854996, Test Loss: 0.1655251681804657\n",
            "Epoch: 189, Train Loss: 0.04211072623729706, Test Loss: 0.16588571667671204\n",
            "Epoch: 190, Train Loss: 0.04198675975203514, Test Loss: 0.16373035311698914\n",
            "Epoch: 191, Train Loss: 0.04219891503453255, Test Loss: 0.16626416146755219\n",
            "Epoch: 192, Train Loss: 0.042041897773742676, Test Loss: 0.16398951411247253\n",
            "Epoch: 193, Train Loss: 0.04238509014248848, Test Loss: 0.16281983256340027\n",
            "Epoch: 194, Train Loss: 0.041760433465242386, Test Loss: 0.1627102792263031\n",
            "Epoch: 195, Train Loss: 0.04199371486902237, Test Loss: 0.16348840296268463\n",
            "Epoch: 196, Train Loss: 0.042043089866638184, Test Loss: 0.16378480195999146\n",
            "Epoch: 197, Train Loss: 0.0418134443461895, Test Loss: 0.16416417062282562\n",
            "Epoch: 198, Train Loss: 0.042362768203020096, Test Loss: 0.16549356281757355\n",
            "Epoch: 199, Train Loss: 0.041291218250989914, Test Loss: 0.16349655389785767\n",
            "Epoch: 200, Train Loss: 0.04253513738512993, Test Loss: 0.1642460972070694\n",
            "Epoch: 201, Train Loss: 0.04281066730618477, Test Loss: 0.16642263531684875\n",
            "Epoch: 202, Train Loss: 0.0420285128057003, Test Loss: 0.16345617175102234\n",
            "Epoch: 203, Train Loss: 0.04120137542486191, Test Loss: 0.16275864839553833\n",
            "Epoch: 204, Train Loss: 0.041587673127651215, Test Loss: 0.16164326667785645\n",
            "Epoch: 205, Train Loss: 0.04166807606816292, Test Loss: 0.1628842055797577\n",
            "Epoch: 206, Train Loss: 0.04113144800066948, Test Loss: 0.16230323910713196\n",
            "Epoch: 207, Train Loss: 0.0418480820953846, Test Loss: 0.16351747512817383\n",
            "Epoch: 208, Train Loss: 0.041558582335710526, Test Loss: 0.1597234010696411\n",
            "Epoch: 209, Train Loss: 0.041739851236343384, Test Loss: 0.16163966059684753\n",
            "Epoch: 210, Train Loss: 0.04149793088436127, Test Loss: 0.16397428512573242\n",
            "Epoch: 211, Train Loss: 0.041224878281354904, Test Loss: 0.16321538388729095\n",
            "Epoch: 212, Train Loss: 0.04138394072651863, Test Loss: 0.16055813431739807\n",
            "Epoch: 213, Train Loss: 0.041349273175001144, Test Loss: 0.16077987849712372\n",
            "Epoch: 214, Train Loss: 0.0412277989089489, Test Loss: 0.16079241037368774\n",
            "Epoch: 215, Train Loss: 0.04164084792137146, Test Loss: 0.16149508953094482\n",
            "Epoch: 216, Train Loss: 0.041888657957315445, Test Loss: 0.16099362075328827\n",
            "Epoch: 217, Train Loss: 0.042391546070575714, Test Loss: 0.15877796709537506\n",
            "Epoch: 218, Train Loss: 0.04155391827225685, Test Loss: 0.15855611860752106\n",
            "Epoch: 219, Train Loss: 0.04191366955637932, Test Loss: 0.16019849479198456\n",
            "Epoch: 220, Train Loss: 0.04197759926319122, Test Loss: 0.16259081661701202\n",
            "Epoch: 221, Train Loss: 0.041121624410152435, Test Loss: 0.16087867319583893\n",
            "Epoch: 222, Train Loss: 0.0420936644077301, Test Loss: 0.16037973761558533\n",
            "Epoch: 223, Train Loss: 0.04124661907553673, Test Loss: 0.1588229387998581\n",
            "Epoch: 224, Train Loss: 0.04104471206665039, Test Loss: 0.15994836390018463\n",
            "Epoch: 225, Train Loss: 0.041348643600940704, Test Loss: 0.15955395996570587\n",
            "Epoch: 226, Train Loss: 0.04192773997783661, Test Loss: 0.15994606912136078\n",
            "Epoch: 227, Train Loss: 0.04137609526515007, Test Loss: 0.1592499017715454\n",
            "Epoch: 228, Train Loss: 0.04091940075159073, Test Loss: 0.15959346294403076\n",
            "Epoch: 229, Train Loss: 0.041217345744371414, Test Loss: 0.15932214260101318\n",
            "Epoch: 230, Train Loss: 0.04160583019256592, Test Loss: 0.157194122672081\n",
            "Epoch: 231, Train Loss: 0.04123126342892647, Test Loss: 0.1603057086467743\n",
            "Epoch: 232, Train Loss: 0.04138908535242081, Test Loss: 0.15931536257266998\n",
            "Epoch: 233, Train Loss: 0.04160658270120621, Test Loss: 0.15764951705932617\n",
            "Epoch: 234, Train Loss: 0.04189393296837807, Test Loss: 0.15883955359458923\n",
            "Epoch: 235, Train Loss: 0.04177766293287277, Test Loss: 0.1575821489095688\n",
            "Epoch: 236, Train Loss: 0.04081636667251587, Test Loss: 0.15613052248954773\n",
            "Epoch: 237, Train Loss: 0.041623808443546295, Test Loss: 0.15758481621742249\n",
            "Epoch: 238, Train Loss: 0.04097984731197357, Test Loss: 0.15951408445835114\n",
            "Epoch: 239, Train Loss: 0.041086386889219284, Test Loss: 0.15887586772441864\n",
            "Epoch: 240, Train Loss: 0.04073667526245117, Test Loss: 0.1571541577577591\n",
            "Epoch: 241, Train Loss: 0.040802303701639175, Test Loss: 0.15728311240673065\n",
            "Epoch: 242, Train Loss: 0.041147999465465546, Test Loss: 0.1586049646139145\n",
            "Epoch: 243, Train Loss: 0.041285641491413116, Test Loss: 0.15931658446788788\n",
            "Epoch: 244, Train Loss: 0.0412239208817482, Test Loss: 0.15704230964183807\n",
            "Epoch: 245, Train Loss: 0.04159901663661003, Test Loss: 0.15603546798229218\n",
            "Epoch: 246, Train Loss: 0.04028458148241043, Test Loss: 0.15567928552627563\n",
            "Epoch: 247, Train Loss: 0.04113151878118515, Test Loss: 0.15715576708316803\n",
            "Epoch: 248, Train Loss: 0.04112793877720833, Test Loss: 0.15460674464702606\n",
            "Epoch: 249, Train Loss: 0.04122085124254227, Test Loss: 0.1546451598405838\n",
            "Epoch: 250, Train Loss: 0.04121683910489082, Test Loss: 0.1541450023651123\n",
            "Epoch: 251, Train Loss: 0.04074576124548912, Test Loss: 0.15616269409656525\n",
            "Epoch: 252, Train Loss: 0.04113898426294327, Test Loss: 0.156926229596138\n",
            "Epoch: 253, Train Loss: 0.041117362678050995, Test Loss: 0.15909840166568756\n",
            "Epoch: 254, Train Loss: 0.041243378072977066, Test Loss: 0.15698134899139404\n",
            "Epoch: 255, Train Loss: 0.041132885962724686, Test Loss: 0.15734221041202545\n",
            "Epoch: 256, Train Loss: 0.04087619110941887, Test Loss: 0.1577444076538086\n",
            "Epoch: 257, Train Loss: 0.04060463607311249, Test Loss: 0.15979735553264618\n",
            "Epoch: 258, Train Loss: 0.04110480099916458, Test Loss: 0.1559688150882721\n",
            "Epoch: 259, Train Loss: 0.04007994011044502, Test Loss: 0.15761378407478333\n",
            "Epoch: 260, Train Loss: 0.041327252984046936, Test Loss: 0.1549879014492035\n",
            "Epoch: 261, Train Loss: 0.04097004607319832, Test Loss: 0.15483492612838745\n",
            "Epoch: 262, Train Loss: 0.04072653129696846, Test Loss: 0.15732088685035706\n",
            "Epoch: 263, Train Loss: 0.04103754088282585, Test Loss: 0.1531476527452469\n",
            "Epoch: 264, Train Loss: 0.03992202505469322, Test Loss: 0.1545654684305191\n",
            "Epoch: 265, Train Loss: 0.04081561788916588, Test Loss: 0.15384873747825623\n",
            "Epoch: 266, Train Loss: 0.04104958102107048, Test Loss: 0.15575309097766876\n",
            "Epoch: 267, Train Loss: 0.041219983249902725, Test Loss: 0.1564888209104538\n",
            "Epoch: 268, Train Loss: 0.04042637348175049, Test Loss: 0.1552911251783371\n",
            "Epoch: 269, Train Loss: 0.04118959978222847, Test Loss: 0.15349942445755005\n",
            "Epoch: 270, Train Loss: 0.041622698307037354, Test Loss: 0.1547650843858719\n",
            "Epoch: 271, Train Loss: 0.04050346091389656, Test Loss: 0.15361158549785614\n",
            "Epoch: 272, Train Loss: 0.04076174646615982, Test Loss: 0.15218637883663177\n",
            "Epoch: 273, Train Loss: 0.04025500267744064, Test Loss: 0.15194976329803467\n",
            "Epoch: 274, Train Loss: 0.040935248136520386, Test Loss: 0.15243253111839294\n",
            "Epoch: 275, Train Loss: 0.040849469602108, Test Loss: 0.15410633385181427\n",
            "Epoch: 276, Train Loss: 0.04045093059539795, Test Loss: 0.15684831142425537\n",
            "Epoch: 277, Train Loss: 0.040119320154190063, Test Loss: 0.15334537625312805\n",
            "Epoch: 278, Train Loss: 0.0408707857131958, Test Loss: 0.15360836684703827\n",
            "Epoch: 279, Train Loss: 0.040044303983449936, Test Loss: 0.15417219698429108\n",
            "Epoch: 280, Train Loss: 0.03982330113649368, Test Loss: 0.15373605489730835\n",
            "Epoch: 281, Train Loss: 0.04080991446971893, Test Loss: 0.1566900759935379\n",
            "Epoch: 282, Train Loss: 0.04047102481126785, Test Loss: 0.14983732998371124\n",
            "Epoch: 283, Train Loss: 0.039488792419433594, Test Loss: 0.1517486423254013\n",
            "Epoch: 284, Train Loss: 0.04017513245344162, Test Loss: 0.15318404138088226\n",
            "Epoch: 285, Train Loss: 0.04021334648132324, Test Loss: 0.1515503227710724\n",
            "Epoch: 286, Train Loss: 0.03969639912247658, Test Loss: 0.15183469653129578\n",
            "Epoch: 287, Train Loss: 0.040271658450365067, Test Loss: 0.14958524703979492\n",
            "Epoch: 288, Train Loss: 0.040003858506679535, Test Loss: 0.1531655192375183\n",
            "Epoch: 289, Train Loss: 0.04065978527069092, Test Loss: 0.15287505090236664\n",
            "Epoch: 290, Train Loss: 0.040416862815618515, Test Loss: 0.15138578414916992\n",
            "Epoch: 291, Train Loss: 0.04057059809565544, Test Loss: 0.148293137550354\n",
            "Epoch: 292, Train Loss: 0.04058483988046646, Test Loss: 0.15048648416996002\n",
            "Epoch: 293, Train Loss: 0.040253546088933945, Test Loss: 0.1510869860649109\n",
            "Epoch: 294, Train Loss: 0.04004218801856041, Test Loss: 0.14894850552082062\n",
            "Epoch: 295, Train Loss: 0.04088430106639862, Test Loss: 0.15067259967327118\n",
            "Epoch: 296, Train Loss: 0.04056604579091072, Test Loss: 0.1513989120721817\n",
            "Epoch: 297, Train Loss: 0.04054242745041847, Test Loss: 0.15138790011405945\n",
            "Epoch: 298, Train Loss: 0.04046371951699257, Test Loss: 0.15150843560695648\n",
            "Epoch: 299, Train Loss: 0.03974498063325882, Test Loss: 0.15233075618743896\n",
            "Epoch: 300, Train Loss: 0.039608247578144073, Test Loss: 0.14969387650489807\n",
            "Epoch: 301, Train Loss: 0.03992288559675217, Test Loss: 0.1529969573020935\n",
            "Epoch: 302, Train Loss: 0.039061039686203, Test Loss: 0.15238057076931\n",
            "Epoch: 303, Train Loss: 0.03978733718395233, Test Loss: 0.14753103256225586\n",
            "Epoch: 304, Train Loss: 0.0396549329161644, Test Loss: 0.14830689132213593\n",
            "Epoch: 305, Train Loss: 0.04005880653858185, Test Loss: 0.15262508392333984\n",
            "Epoch: 306, Train Loss: 0.04033138230443001, Test Loss: 0.15002593398094177\n",
            "Epoch: 307, Train Loss: 0.03973361849784851, Test Loss: 0.1501118391752243\n",
            "Epoch: 308, Train Loss: 0.03988872095942497, Test Loss: 0.1487313061952591\n",
            "Epoch: 309, Train Loss: 0.040317170321941376, Test Loss: 0.14992456138134003\n",
            "Epoch: 310, Train Loss: 0.039627838879823685, Test Loss: 0.15178033709526062\n",
            "Epoch: 311, Train Loss: 0.03947228565812111, Test Loss: 0.14629824459552765\n",
            "Epoch: 312, Train Loss: 0.03998761251568794, Test Loss: 0.14711995422840118\n",
            "Epoch: 313, Train Loss: 0.03945279121398926, Test Loss: 0.14982298016548157\n",
            "Epoch: 314, Train Loss: 0.0397304929792881, Test Loss: 0.15175260603427887\n",
            "Epoch: 315, Train Loss: 0.04023832827806473, Test Loss: 0.14516811072826385\n",
            "Epoch: 316, Train Loss: 0.03999398648738861, Test Loss: 0.14657779037952423\n",
            "Epoch: 317, Train Loss: 0.040345437824726105, Test Loss: 0.14829783141613007\n",
            "Epoch: 318, Train Loss: 0.03962741419672966, Test Loss: 0.1468646079301834\n",
            "Epoch: 319, Train Loss: 0.03936735913157463, Test Loss: 0.14936359226703644\n",
            "Epoch: 320, Train Loss: 0.03934793546795845, Test Loss: 0.14472058415412903\n",
            "Epoch: 321, Train Loss: 0.0394090972840786, Test Loss: 0.1453372687101364\n",
            "Epoch: 322, Train Loss: 0.040110036730766296, Test Loss: 0.14821085333824158\n",
            "Epoch: 323, Train Loss: 0.03992199897766113, Test Loss: 0.14944466948509216\n",
            "Epoch: 324, Train Loss: 0.03928758203983307, Test Loss: 0.14764024317264557\n",
            "Epoch: 325, Train Loss: 0.04042574763298035, Test Loss: 0.1445493996143341\n",
            "Epoch: 326, Train Loss: 0.040473271161317825, Test Loss: 0.1474228948354721\n",
            "Epoch: 327, Train Loss: 0.03930744528770447, Test Loss: 0.14829042553901672\n",
            "Epoch: 328, Train Loss: 0.039987314492464066, Test Loss: 0.14809244871139526\n",
            "Epoch: 329, Train Loss: 0.03971701115369797, Test Loss: 0.14923053979873657\n",
            "Epoch: 330, Train Loss: 0.038871150463819504, Test Loss: 0.1464965045452118\n",
            "Epoch: 331, Train Loss: 0.03918047994375229, Test Loss: 0.1460890769958496\n",
            "Epoch: 332, Train Loss: 0.03892722353339195, Test Loss: 0.14812211692333221\n",
            "Epoch: 333, Train Loss: 0.03907053917646408, Test Loss: 0.14654640853405\n",
            "Epoch: 334, Train Loss: 0.03897852078080177, Test Loss: 0.1471758931875229\n",
            "Epoch: 335, Train Loss: 0.03948621079325676, Test Loss: 0.1446170210838318\n",
            "Epoch: 336, Train Loss: 0.039579715579748154, Test Loss: 0.14673157036304474\n",
            "Epoch: 337, Train Loss: 0.03877294063568115, Test Loss: 0.1448759138584137\n",
            "Epoch: 338, Train Loss: 0.039927318692207336, Test Loss: 0.14673969149589539\n",
            "Epoch: 339, Train Loss: 0.040059853345155716, Test Loss: 0.1473473161458969\n",
            "Epoch: 340, Train Loss: 0.03927087411284447, Test Loss: 0.14716337621212006\n",
            "Epoch: 341, Train Loss: 0.03911649435758591, Test Loss: 0.1462535411119461\n",
            "Epoch: 342, Train Loss: 0.038887158036231995, Test Loss: 0.14626777172088623\n",
            "Epoch: 343, Train Loss: 0.039257388561964035, Test Loss: 0.14595358073711395\n",
            "Epoch: 344, Train Loss: 0.038789574056863785, Test Loss: 0.14707763493061066\n",
            "Epoch: 345, Train Loss: 0.039023708552122116, Test Loss: 0.1466190665960312\n",
            "Epoch: 346, Train Loss: 0.03897058218717575, Test Loss: 0.14644548296928406\n",
            "Epoch: 347, Train Loss: 0.03918357938528061, Test Loss: 0.14747865498065948\n",
            "Epoch: 348, Train Loss: 0.03956867381930351, Test Loss: 0.14731284976005554\n",
            "Epoch: 349, Train Loss: 0.038621269166469574, Test Loss: 0.14341719448566437\n",
            "Epoch: 350, Train Loss: 0.038705501705408096, Test Loss: 0.14479510486125946\n",
            "Epoch: 351, Train Loss: 0.039112113416194916, Test Loss: 0.14512823522090912\n",
            "Epoch: 352, Train Loss: 0.03870508819818497, Test Loss: 0.14721855521202087\n",
            "Epoch: 353, Train Loss: 0.03946199640631676, Test Loss: 0.14267279207706451\n",
            "Epoch: 354, Train Loss: 0.03897671028971672, Test Loss: 0.14436376094818115\n",
            "Epoch: 355, Train Loss: 0.038822777569293976, Test Loss: 0.14507173001766205\n",
            "Epoch: 356, Train Loss: 0.03901132196187973, Test Loss: 0.1462557017803192\n",
            "Epoch: 357, Train Loss: 0.03947119414806366, Test Loss: 0.14625664055347443\n",
            "Epoch: 358, Train Loss: 0.03901360556483269, Test Loss: 0.14409323036670685\n",
            "Epoch: 359, Train Loss: 0.03948115184903145, Test Loss: 0.14388222992420197\n",
            "Epoch: 360, Train Loss: 0.038833022117614746, Test Loss: 0.1475861519575119\n",
            "Epoch: 361, Train Loss: 0.03867075592279434, Test Loss: 0.14621131122112274\n",
            "Epoch: 362, Train Loss: 0.038298316299915314, Test Loss: 0.146392360329628\n",
            "Epoch: 363, Train Loss: 0.03944256529211998, Test Loss: 0.14187361299991608\n",
            "Epoch: 364, Train Loss: 0.0387558676302433, Test Loss: 0.14616766571998596\n",
            "Epoch: 365, Train Loss: 0.03846431523561478, Test Loss: 0.14934173226356506\n",
            "Epoch: 366, Train Loss: 0.03878491371870041, Test Loss: 0.1471165418624878\n",
            "Epoch: 367, Train Loss: 0.038616061210632324, Test Loss: 0.14311131834983826\n",
            "Epoch: 368, Train Loss: 0.03956327214837074, Test Loss: 0.1433306187391281\n",
            "Epoch: 369, Train Loss: 0.03824152052402496, Test Loss: 0.14635398983955383\n",
            "Epoch: 370, Train Loss: 0.03843245655298233, Test Loss: 0.14579908549785614\n",
            "Epoch: 371, Train Loss: 0.03871350735425949, Test Loss: 0.14384514093399048\n",
            "Epoch: 372, Train Loss: 0.03828482702374458, Test Loss: 0.143572136759758\n",
            "Epoch: 373, Train Loss: 0.03922714665532112, Test Loss: 0.14402897655963898\n",
            "Epoch: 374, Train Loss: 0.03909340873360634, Test Loss: 0.14337675273418427\n",
            "Epoch: 375, Train Loss: 0.038751307874917984, Test Loss: 0.14321818947792053\n",
            "Epoch: 376, Train Loss: 0.03869711235165596, Test Loss: 0.13926564157009125\n",
            "Epoch: 377, Train Loss: 0.03883839398622513, Test Loss: 0.14268696308135986\n",
            "Epoch: 378, Train Loss: 0.03896684572100639, Test Loss: 0.1448141187429428\n",
            "Epoch: 379, Train Loss: 0.038420408964157104, Test Loss: 0.14254724979400635\n",
            "Epoch: 380, Train Loss: 0.038885697722435, Test Loss: 0.13895201683044434\n",
            "Epoch: 381, Train Loss: 0.03862832114100456, Test Loss: 0.1406669020652771\n",
            "Epoch: 382, Train Loss: 0.03873221576213837, Test Loss: 0.1416502594947815\n",
            "Epoch: 383, Train Loss: 0.037695955485105515, Test Loss: 0.14184820652008057\n",
            "Epoch: 384, Train Loss: 0.03876980394124985, Test Loss: 0.14171208441257477\n",
            "Epoch: 385, Train Loss: 0.03872711956501007, Test Loss: 0.1411573588848114\n",
            "Epoch: 386, Train Loss: 0.03873198479413986, Test Loss: 0.1399698704481125\n",
            "Epoch: 387, Train Loss: 0.03811502456665039, Test Loss: 0.14390744268894196\n",
            "Epoch: 388, Train Loss: 0.03939628601074219, Test Loss: 0.141181081533432\n",
            "Epoch: 389, Train Loss: 0.03897816315293312, Test Loss: 0.14245404303073883\n",
            "Epoch: 390, Train Loss: 0.03853114694356918, Test Loss: 0.14366167783737183\n",
            "Epoch: 391, Train Loss: 0.03823920711874962, Test Loss: 0.1438756138086319\n",
            "Epoch: 392, Train Loss: 0.038452476263046265, Test Loss: 0.14478573203086853\n",
            "Epoch: 393, Train Loss: 0.039023756980895996, Test Loss: 0.14014676213264465\n",
            "Epoch: 394, Train Loss: 0.037382353097200394, Test Loss: 0.14045637845993042\n",
            "Epoch: 395, Train Loss: 0.037972886115312576, Test Loss: 0.14404334127902985\n",
            "Epoch: 396, Train Loss: 0.03812548890709877, Test Loss: 0.14360983669757843\n",
            "Epoch: 397, Train Loss: 0.0381740964949131, Test Loss: 0.1409928947687149\n",
            "Epoch: 398, Train Loss: 0.03809183090925217, Test Loss: 0.1412360668182373\n",
            "Epoch: 399, Train Loss: 0.03836598992347717, Test Loss: 0.14107723534107208\n",
            "Epoch: 400, Train Loss: 0.03864819183945656, Test Loss: 0.13972346484661102\n",
            "Epoch: 401, Train Loss: 0.03862765058875084, Test Loss: 0.14197058975696564\n",
            "Epoch: 402, Train Loss: 0.03764784708619118, Test Loss: 0.14167971909046173\n",
            "Epoch: 403, Train Loss: 0.03813716769218445, Test Loss: 0.1419273018836975\n",
            "Epoch: 404, Train Loss: 0.03808194398880005, Test Loss: 0.139179989695549\n",
            "Epoch: 405, Train Loss: 0.038434967398643494, Test Loss: 0.13975971937179565\n",
            "Epoch: 406, Train Loss: 0.03801584988832474, Test Loss: 0.14207248389720917\n",
            "Epoch: 407, Train Loss: 0.03749486804008484, Test Loss: 0.14306855201721191\n",
            "Epoch: 408, Train Loss: 0.0377354770898819, Test Loss: 0.13878218829631805\n",
            "Epoch: 409, Train Loss: 0.038176558911800385, Test Loss: 0.13826702535152435\n",
            "Epoch: 410, Train Loss: 0.03766385093331337, Test Loss: 0.13871780037879944\n",
            "Epoch: 411, Train Loss: 0.03749920800328255, Test Loss: 0.1387786865234375\n",
            "Epoch: 412, Train Loss: 0.03757777810096741, Test Loss: 0.1374843418598175\n",
            "Epoch: 413, Train Loss: 0.03774966672062874, Test Loss: 0.13949182629585266\n",
            "Epoch: 414, Train Loss: 0.03794947639107704, Test Loss: 0.1391347348690033\n",
            "Epoch: 415, Train Loss: 0.03811780735850334, Test Loss: 0.13569098711013794\n",
            "Epoch: 416, Train Loss: 0.038146138191223145, Test Loss: 0.1375989317893982\n",
            "Epoch: 417, Train Loss: 0.03792084753513336, Test Loss: 0.13685451447963715\n",
            "Epoch: 418, Train Loss: 0.03836289048194885, Test Loss: 0.1381145715713501\n",
            "Epoch: 419, Train Loss: 0.037176672369241714, Test Loss: 0.13757801055908203\n",
            "Epoch: 420, Train Loss: 0.03798951581120491, Test Loss: 0.1362723857164383\n",
            "Epoch: 421, Train Loss: 0.03789380192756653, Test Loss: 0.1380758136510849\n",
            "Epoch: 422, Train Loss: 0.03748684376478195, Test Loss: 0.13792158663272858\n",
            "Epoch: 423, Train Loss: 0.03811223804950714, Test Loss: 0.13666240870952606\n",
            "Epoch: 424, Train Loss: 0.03787150979042053, Test Loss: 0.13824781775474548\n",
            "Epoch: 425, Train Loss: 0.037573449313640594, Test Loss: 0.13962911069393158\n",
            "Epoch: 426, Train Loss: 0.03898771107196808, Test Loss: 0.13923171162605286\n",
            "Epoch: 427, Train Loss: 0.03719765692949295, Test Loss: 0.13500595092773438\n",
            "Epoch: 428, Train Loss: 0.03792867809534073, Test Loss: 0.13711510598659515\n",
            "Epoch: 429, Train Loss: 0.038158807903528214, Test Loss: 0.14195261895656586\n",
            "Epoch: 430, Train Loss: 0.03792679309844971, Test Loss: 0.13913680613040924\n",
            "Epoch: 431, Train Loss: 0.03787308186292648, Test Loss: 0.13793805241584778\n",
            "Epoch: 432, Train Loss: 0.03760593384504318, Test Loss: 0.1393814980983734\n",
            "Epoch: 433, Train Loss: 0.038207679986953735, Test Loss: 0.1402706354856491\n",
            "Epoch: 434, Train Loss: 0.03727616369724274, Test Loss: 0.14082074165344238\n",
            "Epoch: 435, Train Loss: 0.03745155781507492, Test Loss: 0.13811635971069336\n",
            "Epoch: 436, Train Loss: 0.0372382216155529, Test Loss: 0.1388373076915741\n",
            "Epoch: 437, Train Loss: 0.036998484283685684, Test Loss: 0.14035023748874664\n",
            "Epoch: 438, Train Loss: 0.037754666060209274, Test Loss: 0.13808347284793854\n",
            "Epoch: 439, Train Loss: 0.03792223334312439, Test Loss: 0.13723935186862946\n",
            "Epoch: 440, Train Loss: 0.03726284205913544, Test Loss: 0.1358429342508316\n",
            "Epoch: 441, Train Loss: 0.03740561380982399, Test Loss: 0.1412646472454071\n",
            "Epoch: 442, Train Loss: 0.03718631714582443, Test Loss: 0.13713285326957703\n",
            "Epoch: 443, Train Loss: 0.03769615665078163, Test Loss: 0.13678069412708282\n",
            "Epoch: 444, Train Loss: 0.03751702234148979, Test Loss: 0.13614559173583984\n",
            "Epoch: 445, Train Loss: 0.03731190040707588, Test Loss: 0.1392814815044403\n",
            "Epoch: 446, Train Loss: 0.038125474005937576, Test Loss: 0.1396600604057312\n",
            "Epoch: 447, Train Loss: 0.03732603043317795, Test Loss: 0.136704683303833\n",
            "Epoch: 448, Train Loss: 0.03761092945933342, Test Loss: 0.13634902238845825\n",
            "Epoch: 449, Train Loss: 0.03736644238233566, Test Loss: 0.13505588471889496\n",
            "Epoch: 450, Train Loss: 0.036321043968200684, Test Loss: 0.1368611752986908\n",
            "Epoch: 451, Train Loss: 0.037469469010829926, Test Loss: 0.1367650181055069\n",
            "Epoch: 452, Train Loss: 0.037134941667318344, Test Loss: 0.1392872929573059\n",
            "Epoch: 453, Train Loss: 0.0370749793946743, Test Loss: 0.13594771921634674\n",
            "Epoch: 454, Train Loss: 0.037502653896808624, Test Loss: 0.13756410777568817\n",
            "Epoch: 455, Train Loss: 0.037042856216430664, Test Loss: 0.13887028396129608\n",
            "Epoch: 456, Train Loss: 0.036465853452682495, Test Loss: 0.1381848007440567\n",
            "Epoch: 457, Train Loss: 0.037172429263591766, Test Loss: 0.13633191585540771\n",
            "Epoch: 458, Train Loss: 0.03668781369924545, Test Loss: 0.13720811903476715\n",
            "Epoch: 459, Train Loss: 0.03697676956653595, Test Loss: 0.13954712450504303\n",
            "Epoch: 460, Train Loss: 0.03734283521771431, Test Loss: 0.1331392526626587\n",
            "Epoch: 461, Train Loss: 0.03721556067466736, Test Loss: 0.13501042127609253\n",
            "Epoch: 462, Train Loss: 0.03735122084617615, Test Loss: 0.13622021675109863\n",
            "Epoch: 463, Train Loss: 0.03767161816358566, Test Loss: 0.13636016845703125\n",
            "Epoch: 464, Train Loss: 0.03779415786266327, Test Loss: 0.13585126399993896\n",
            "Epoch: 465, Train Loss: 0.03698370233178139, Test Loss: 0.13462430238723755\n",
            "Epoch: 466, Train Loss: 0.036223720759153366, Test Loss: 0.13545307517051697\n",
            "Epoch: 467, Train Loss: 0.037235621362924576, Test Loss: 0.13709725439548492\n",
            "Epoch: 468, Train Loss: 0.03745380416512489, Test Loss: 0.13853108882904053\n",
            "Epoch: 469, Train Loss: 0.03650381788611412, Test Loss: 0.1366157829761505\n",
            "Epoch: 470, Train Loss: 0.03709559142589569, Test Loss: 0.13731424510478973\n",
            "Epoch: 471, Train Loss: 0.037571925669908524, Test Loss: 0.13536342978477478\n",
            "Epoch: 472, Train Loss: 0.037305280566215515, Test Loss: 0.13547426462173462\n",
            "Epoch: 473, Train Loss: 0.03717303276062012, Test Loss: 0.13876213133335114\n",
            "Epoch: 474, Train Loss: 0.03724910691380501, Test Loss: 0.1359570473432541\n",
            "Epoch: 475, Train Loss: 0.03671956807374954, Test Loss: 0.13537420332431793\n",
            "Epoch: 476, Train Loss: 0.037351831793785095, Test Loss: 0.13583502173423767\n",
            "Epoch: 477, Train Loss: 0.03738868236541748, Test Loss: 0.13567304611206055\n",
            "Epoch: 478, Train Loss: 0.03718177601695061, Test Loss: 0.1361110657453537\n",
            "Epoch: 479, Train Loss: 0.03666059300303459, Test Loss: 0.13359946012496948\n",
            "Epoch: 480, Train Loss: 0.03654708340764046, Test Loss: 0.13493376970291138\n",
            "Epoch: 481, Train Loss: 0.03710546717047691, Test Loss: 0.13417302072048187\n",
            "Epoch: 482, Train Loss: 0.03702247515320778, Test Loss: 0.1370641142129898\n",
            "Epoch: 483, Train Loss: 0.03680897876620293, Test Loss: 0.13781005144119263\n",
            "Epoch: 484, Train Loss: 0.03653791919350624, Test Loss: 0.13502490520477295\n",
            "Epoch: 485, Train Loss: 0.03675629198551178, Test Loss: 0.13435113430023193\n",
            "Epoch: 486, Train Loss: 0.03656765818595886, Test Loss: 0.1351364701986313\n",
            "Epoch: 487, Train Loss: 0.03635456785559654, Test Loss: 0.1355682611465454\n",
            "Epoch: 488, Train Loss: 0.036920156329870224, Test Loss: 0.13405883312225342\n",
            "Epoch: 489, Train Loss: 0.03697635605931282, Test Loss: 0.13279758393764496\n",
            "Epoch: 490, Train Loss: 0.03698594495654106, Test Loss: 0.13291703164577484\n",
            "Epoch: 491, Train Loss: 0.03633957356214523, Test Loss: 0.13726679980754852\n",
            "Epoch: 492, Train Loss: 0.03669819235801697, Test Loss: 0.135862335562706\n",
            "Epoch: 493, Train Loss: 0.035880062729120255, Test Loss: 0.13359735906124115\n",
            "Epoch: 494, Train Loss: 0.03740214928984642, Test Loss: 0.1327708214521408\n",
            "Epoch: 495, Train Loss: 0.03703177720308304, Test Loss: 0.13559003174304962\n",
            "Epoch: 496, Train Loss: 0.03674810752272606, Test Loss: 0.1377604454755783\n",
            "Epoch: 497, Train Loss: 0.03705247491598129, Test Loss: 0.13608455657958984\n",
            "Epoch: 498, Train Loss: 0.03656694293022156, Test Loss: 0.1318310797214508\n",
            "Epoch: 499, Train Loss: 0.036352481693029404, Test Loss: 0.13657182455062866\n",
            "Epoch: 500, Train Loss: 0.03560847043991089, Test Loss: 0.1392216682434082\n",
            "Epoch: 501, Train Loss: 0.03613290190696716, Test Loss: 0.1361968219280243\n",
            "Epoch: 502, Train Loss: 0.03636269271373749, Test Loss: 0.13333898782730103\n",
            "Epoch: 503, Train Loss: 0.036723244935274124, Test Loss: 0.13378772139549255\n",
            "Epoch: 504, Train Loss: 0.03667620196938515, Test Loss: 0.13572199642658234\n",
            "Epoch: 505, Train Loss: 0.03601321205496788, Test Loss: 0.1353577822446823\n",
            "Epoch: 506, Train Loss: 0.03580957651138306, Test Loss: 0.13268110156059265\n",
            "Epoch: 507, Train Loss: 0.03619551658630371, Test Loss: 0.13008901476860046\n",
            "Epoch: 508, Train Loss: 0.036067161709070206, Test Loss: 0.1339755654335022\n",
            "Epoch: 509, Train Loss: 0.03594319522380829, Test Loss: 0.13499413430690765\n",
            "Epoch: 510, Train Loss: 0.035848814994096756, Test Loss: 0.1314661055803299\n",
            "Epoch: 511, Train Loss: 0.0369088388979435, Test Loss: 0.12954750657081604\n",
            "Epoch: 512, Train Loss: 0.03662365302443504, Test Loss: 0.1338508576154709\n",
            "Epoch: 513, Train Loss: 0.035846494138240814, Test Loss: 0.13774901628494263\n",
            "Epoch: 514, Train Loss: 0.035723429173231125, Test Loss: 0.13445882499217987\n",
            "Epoch: 515, Train Loss: 0.03609498217701912, Test Loss: 0.13246694207191467\n",
            "Epoch: 516, Train Loss: 0.03666575998067856, Test Loss: 0.13317462801933289\n",
            "Epoch: 517, Train Loss: 0.036037106066942215, Test Loss: 0.1354944407939911\n",
            "Epoch: 518, Train Loss: 0.036028698086738586, Test Loss: 0.13834181427955627\n",
            "Epoch: 519, Train Loss: 0.036004163324832916, Test Loss: 0.1343865692615509\n",
            "Epoch: 520, Train Loss: 0.036098845303058624, Test Loss: 0.1336679309606552\n",
            "Epoch: 521, Train Loss: 0.03595029562711716, Test Loss: 0.13327182829380035\n",
            "Epoch: 522, Train Loss: 0.03600845858454704, Test Loss: 0.13685010373592377\n",
            "Epoch: 523, Train Loss: 0.03611022233963013, Test Loss: 0.13616180419921875\n",
            "Epoch: 524, Train Loss: 0.03604644909501076, Test Loss: 0.13491782546043396\n",
            "Epoch: 525, Train Loss: 0.03603491932153702, Test Loss: 0.13138417899608612\n",
            "Epoch: 526, Train Loss: 0.035758376121520996, Test Loss: 0.1353231519460678\n",
            "Epoch: 527, Train Loss: 0.03590686619281769, Test Loss: 0.13605326414108276\n",
            "Epoch: 528, Train Loss: 0.036208897829055786, Test Loss: 0.1344131976366043\n",
            "Epoch: 529, Train Loss: 0.03520510345697403, Test Loss: 0.1324690282344818\n",
            "Epoch: 530, Train Loss: 0.035761091858148575, Test Loss: 0.1333395391702652\n",
            "Epoch: 531, Train Loss: 0.035863522440195084, Test Loss: 0.13501092791557312\n",
            "Epoch: 532, Train Loss: 0.0360744446516037, Test Loss: 0.1339559108018875\n",
            "Epoch: 533, Train Loss: 0.03537312522530556, Test Loss: 0.13115577399730682\n",
            "Epoch: 534, Train Loss: 0.03570965677499771, Test Loss: 0.133672297000885\n",
            "Epoch: 535, Train Loss: 0.03558781370520592, Test Loss: 0.1355472207069397\n",
            "Epoch: 536, Train Loss: 0.03541868180036545, Test Loss: 0.13359524309635162\n",
            "Epoch: 537, Train Loss: 0.035350602120161057, Test Loss: 0.13113318383693695\n",
            "Epoch: 538, Train Loss: 0.03628809005022049, Test Loss: 0.13313233852386475\n",
            "Epoch: 539, Train Loss: 0.03535538911819458, Test Loss: 0.1328667849302292\n",
            "Epoch: 540, Train Loss: 0.03652887046337128, Test Loss: 0.13276733458042145\n",
            "Epoch: 541, Train Loss: 0.03487630933523178, Test Loss: 0.1349729746580124\n",
            "Epoch: 542, Train Loss: 0.03459063544869423, Test Loss: 0.13172075152397156\n",
            "Epoch: 543, Train Loss: 0.03490844741463661, Test Loss: 0.13148583471775055\n",
            "Epoch: 544, Train Loss: 0.035774290561676025, Test Loss: 0.1338660567998886\n",
            "Epoch: 545, Train Loss: 0.03567522391676903, Test Loss: 0.1338670551776886\n",
            "Epoch: 546, Train Loss: 0.036375511437654495, Test Loss: 0.1304776817560196\n",
            "Epoch: 547, Train Loss: 0.03506606072187424, Test Loss: 0.13259844481945038\n",
            "Epoch: 548, Train Loss: 0.036292530596256256, Test Loss: 0.13530896604061127\n",
            "Epoch: 549, Train Loss: 0.03589253127574921, Test Loss: 0.13486459851264954\n",
            "Epoch: 550, Train Loss: 0.035689663141965866, Test Loss: 0.13405287265777588\n",
            "Epoch: 551, Train Loss: 0.03544863685965538, Test Loss: 0.13455082476139069\n",
            "Epoch: 552, Train Loss: 0.035542622208595276, Test Loss: 0.13285762071609497\n",
            "Epoch: 553, Train Loss: 0.03576161712408066, Test Loss: 0.1352006494998932\n",
            "Epoch: 554, Train Loss: 0.03512231633067131, Test Loss: 0.13696064054965973\n",
            "Epoch: 555, Train Loss: 0.0349130779504776, Test Loss: 0.13539454340934753\n",
            "Epoch: 556, Train Loss: 0.035397738218307495, Test Loss: 0.13235211372375488\n",
            "Epoch: 557, Train Loss: 0.03562219440937042, Test Loss: 0.13247589766979218\n",
            "Epoch: 558, Train Loss: 0.03487969934940338, Test Loss: 0.13332624733448029\n",
            "Epoch: 559, Train Loss: 0.035333409905433655, Test Loss: 0.1356395184993744\n",
            "Epoch: 560, Train Loss: 0.03536002337932587, Test Loss: 0.13306324183940887\n",
            "Epoch: 561, Train Loss: 0.03529858589172363, Test Loss: 0.12989826500415802\n",
            "Epoch: 562, Train Loss: 0.035102855414152145, Test Loss: 0.13037370145320892\n",
            "Epoch: 563, Train Loss: 0.03525746241211891, Test Loss: 0.1297861784696579\n",
            "Epoch: 564, Train Loss: 0.03500573709607124, Test Loss: 0.1314184069633484\n",
            "Epoch: 565, Train Loss: 0.03553573414683342, Test Loss: 0.13052591681480408\n",
            "Epoch: 566, Train Loss: 0.03544045239686966, Test Loss: 0.13175205886363983\n",
            "Epoch: 567, Train Loss: 0.03501633554697037, Test Loss: 0.1346277892589569\n",
            "Epoch: 568, Train Loss: 0.03474343195557594, Test Loss: 0.13540175557136536\n",
            "Epoch: 569, Train Loss: 0.035186003893613815, Test Loss: 0.13362333178520203\n",
            "Epoch: 570, Train Loss: 0.03555242344737053, Test Loss: 0.13349033892154694\n",
            "Epoch: 571, Train Loss: 0.03538648411631584, Test Loss: 0.1319369673728943\n",
            "Epoch: 572, Train Loss: 0.03591059893369675, Test Loss: 0.13443835079669952\n",
            "Epoch: 573, Train Loss: 0.03512163832783699, Test Loss: 0.13410864770412445\n",
            "Epoch: 574, Train Loss: 0.03563143312931061, Test Loss: 0.1355333924293518\n",
            "Epoch: 575, Train Loss: 0.034978073090314865, Test Loss: 0.1354375034570694\n",
            "Epoch: 576, Train Loss: 0.035697732120752335, Test Loss: 0.13424623012542725\n",
            "Epoch: 577, Train Loss: 0.03524174913764, Test Loss: 0.1359522044658661\n",
            "Epoch: 578, Train Loss: 0.03551292419433594, Test Loss: 0.13591594994068146\n",
            "Epoch: 579, Train Loss: 0.03505626693367958, Test Loss: 0.13417702913284302\n",
            "Epoch: 580, Train Loss: 0.03591864928603172, Test Loss: 0.1361742913722992\n",
            "Epoch: 581, Train Loss: 0.03554362803697586, Test Loss: 0.13209280371665955\n",
            "Epoch: 582, Train Loss: 0.03507809713482857, Test Loss: 0.1320330947637558\n",
            "Epoch: 583, Train Loss: 0.035294972360134125, Test Loss: 0.13487622141838074\n",
            "Epoch: 584, Train Loss: 0.03487863764166832, Test Loss: 0.13179540634155273\n",
            "Epoch: 585, Train Loss: 0.034463487565517426, Test Loss: 0.1315562129020691\n",
            "Epoch: 586, Train Loss: 0.03436059132218361, Test Loss: 0.1332339644432068\n",
            "Epoch: 587, Train Loss: 0.035519495606422424, Test Loss: 0.13327458500862122\n",
            "Epoch: 588, Train Loss: 0.03544936701655388, Test Loss: 0.13498976826667786\n",
            "Epoch: 589, Train Loss: 0.0340583473443985, Test Loss: 0.13112299144268036\n",
            "Epoch: 590, Train Loss: 0.034989796578884125, Test Loss: 0.13418476283550262\n",
            "Epoch: 591, Train Loss: 0.03523053601384163, Test Loss: 0.1347682923078537\n",
            "Epoch: 592, Train Loss: 0.03465062379837036, Test Loss: 0.13427408039569855\n",
            "Epoch: 593, Train Loss: 0.035349491983652115, Test Loss: 0.13229645788669586\n",
            "Epoch: 594, Train Loss: 0.034394487738609314, Test Loss: 0.13256308436393738\n",
            "Epoch: 595, Train Loss: 0.03483578562736511, Test Loss: 0.13411125540733337\n",
            "Epoch: 596, Train Loss: 0.03409959748387337, Test Loss: 0.13771745562553406\n",
            "Epoch: 597, Train Loss: 0.03486892953515053, Test Loss: 0.1378488391637802\n",
            "Epoch: 598, Train Loss: 0.0350971482694149, Test Loss: 0.13433480262756348\n",
            "Epoch: 599, Train Loss: 0.034336529672145844, Test Loss: 0.1353253424167633\n",
            "Epoch: 600, Train Loss: 0.03440327197313309, Test Loss: 0.13628679513931274\n",
            "Epoch: 601, Train Loss: 0.03512800857424736, Test Loss: 0.13565847277641296\n",
            "Epoch: 602, Train Loss: 0.034106362611055374, Test Loss: 0.13347730040550232\n",
            "Epoch: 603, Train Loss: 0.03452060744166374, Test Loss: 0.13357894122600555\n",
            "Epoch: 604, Train Loss: 0.034722115844488144, Test Loss: 0.13333511352539062\n",
            "Epoch: 605, Train Loss: 0.03419824317097664, Test Loss: 0.13130192458629608\n",
            "Epoch: 606, Train Loss: 0.03467448055744171, Test Loss: 0.13184724748134613\n",
            "Epoch: 607, Train Loss: 0.03423572704195976, Test Loss: 0.13131502270698547\n",
            "Epoch: 608, Train Loss: 0.0342375673353672, Test Loss: 0.12977108359336853\n",
            "Epoch: 609, Train Loss: 0.033725082874298096, Test Loss: 0.12991464138031006\n",
            "Epoch: 610, Train Loss: 0.03435986861586571, Test Loss: 0.13090378046035767\n",
            "Epoch: 611, Train Loss: 0.034670017659664154, Test Loss: 0.13158094882965088\n",
            "Epoch: 612, Train Loss: 0.03429180756211281, Test Loss: 0.13029222190380096\n",
            "Epoch: 613, Train Loss: 0.03428187593817711, Test Loss: 0.1281995177268982\n",
            "Epoch: 614, Train Loss: 0.03478773683309555, Test Loss: 0.1314050555229187\n",
            "Epoch: 615, Train Loss: 0.03400900214910507, Test Loss: 0.13171695172786713\n",
            "Epoch: 616, Train Loss: 0.034404851496219635, Test Loss: 0.13528507947921753\n",
            "Epoch: 617, Train Loss: 0.034565411508083344, Test Loss: 0.13301673531532288\n",
            "Epoch: 618, Train Loss: 0.03450153395533562, Test Loss: 0.1311815232038498\n",
            "Epoch: 619, Train Loss: 0.033597394824028015, Test Loss: 0.13549426198005676\n",
            "Epoch: 620, Train Loss: 0.033569324761629105, Test Loss: 0.13343851268291473\n",
            "Epoch: 621, Train Loss: 0.034301336854696274, Test Loss: 0.13319526612758636\n",
            "Epoch: 622, Train Loss: 0.03390826657414436, Test Loss: 0.1313294619321823\n",
            "Epoch: 623, Train Loss: 0.03443222492933273, Test Loss: 0.1298471838235855\n",
            "Epoch: 624, Train Loss: 0.03499456122517586, Test Loss: 0.1307198703289032\n",
            "Epoch: 625, Train Loss: 0.03430231660604477, Test Loss: 0.13132241368293762\n",
            "Epoch: 626, Train Loss: 0.034376490861177444, Test Loss: 0.1340547651052475\n",
            "Epoch: 627, Train Loss: 0.033956222236156464, Test Loss: 0.13292531669139862\n",
            "Epoch: 628, Train Loss: 0.03436809033155441, Test Loss: 0.13285966217517853\n",
            "Epoch: 629, Train Loss: 0.03448206186294556, Test Loss: 0.1327964812517166\n",
            "Epoch: 630, Train Loss: 0.033807557076215744, Test Loss: 0.13165134191513062\n",
            "Epoch: 631, Train Loss: 0.03442366048693657, Test Loss: 0.13304011523723602\n",
            "Epoch: 632, Train Loss: 0.03371540457010269, Test Loss: 0.1354736089706421\n",
            "Epoch: 633, Train Loss: 0.03358377516269684, Test Loss: 0.13293415307998657\n",
            "Epoch: 634, Train Loss: 0.03401515632867813, Test Loss: 0.13319280743598938\n",
            "Epoch: 635, Train Loss: 0.034421030431985855, Test Loss: 0.13529831171035767\n",
            "Epoch: 636, Train Loss: 0.03365422040224075, Test Loss: 0.13383778929710388\n",
            "Epoch: 637, Train Loss: 0.03439457714557648, Test Loss: 0.12935201823711395\n",
            "Epoch: 638, Train Loss: 0.034189097583293915, Test Loss: 0.13313229382038116\n",
            "Epoch: 639, Train Loss: 0.03448493406176567, Test Loss: 0.1348615288734436\n",
            "Epoch: 640, Train Loss: 0.03368522226810455, Test Loss: 0.13514147698879242\n",
            "Epoch: 641, Train Loss: 0.03386826813220978, Test Loss: 0.13382697105407715\n",
            "Epoch: 642, Train Loss: 0.03415021300315857, Test Loss: 0.13519442081451416\n",
            "Epoch: 643, Train Loss: 0.03454970568418503, Test Loss: 0.13790567219257355\n",
            "Epoch: 644, Train Loss: 0.034092191606760025, Test Loss: 0.1366630643606186\n",
            "Epoch: 645, Train Loss: 0.033910177648067474, Test Loss: 0.13614521920681\n",
            "Epoch: 646, Train Loss: 0.03407538682222366, Test Loss: 0.1349180042743683\n",
            "Epoch: 647, Train Loss: 0.034496307373046875, Test Loss: 0.1333755999803543\n",
            "Epoch: 648, Train Loss: 0.0334416925907135, Test Loss: 0.13470359146595\n",
            "Epoch: 649, Train Loss: 0.033501800149679184, Test Loss: 0.13438425958156586\n",
            "Epoch: 650, Train Loss: 0.034081969410181046, Test Loss: 0.13605532050132751\n",
            "Epoch: 651, Train Loss: 0.03344876691699028, Test Loss: 0.13273227214813232\n",
            "Epoch: 652, Train Loss: 0.034121204167604446, Test Loss: 0.13105426728725433\n",
            "Epoch: 653, Train Loss: 0.03377863019704819, Test Loss: 0.1310456246137619\n",
            "Epoch: 654, Train Loss: 0.03399945795536041, Test Loss: 0.13028334081172943\n",
            "Epoch: 655, Train Loss: 0.03407539799809456, Test Loss: 0.13278962671756744\n",
            "Epoch: 656, Train Loss: 0.033518195152282715, Test Loss: 0.13127928972244263\n",
            "Epoch: 657, Train Loss: 0.03289978578686714, Test Loss: 0.12991607189178467\n",
            "Epoch: 658, Train Loss: 0.033734798431396484, Test Loss: 0.13086721301078796\n",
            "Epoch: 659, Train Loss: 0.03364836424589157, Test Loss: 0.13470497727394104\n",
            "Epoch: 660, Train Loss: 0.033836182206869125, Test Loss: 0.13242092728614807\n",
            "Epoch: 661, Train Loss: 0.033642854541540146, Test Loss: 0.13323764503002167\n",
            "Epoch: 662, Train Loss: 0.033763688057661057, Test Loss: 0.13226774334907532\n",
            "Epoch: 663, Train Loss: 0.03380441293120384, Test Loss: 0.1327611804008484\n",
            "Epoch: 664, Train Loss: 0.03295501321554184, Test Loss: 0.13089776039123535\n",
            "Epoch: 665, Train Loss: 0.033543042838573456, Test Loss: 0.13216640055179596\n",
            "Epoch: 666, Train Loss: 0.03355894610285759, Test Loss: 0.12694519758224487\n",
            "Epoch: 667, Train Loss: 0.033786479383707047, Test Loss: 0.1293160766363144\n",
            "Epoch: 668, Train Loss: 0.033658117055892944, Test Loss: 0.1296478509902954\n",
            "Epoch: 669, Train Loss: 0.03406674042344093, Test Loss: 0.13158951699733734\n",
            "Epoch: 670, Train Loss: 0.03382362797856331, Test Loss: 0.13030695915222168\n",
            "Epoch: 671, Train Loss: 0.03303391486406326, Test Loss: 0.1306816041469574\n",
            "Epoch: 672, Train Loss: 0.03373594209551811, Test Loss: 0.13099519908428192\n",
            "Epoch: 673, Train Loss: 0.03341969475150108, Test Loss: 0.13443425297737122\n",
            "Epoch: 674, Train Loss: 0.033924832940101624, Test Loss: 0.13516128063201904\n",
            "Epoch: 675, Train Loss: 0.03334631398320198, Test Loss: 0.13077965378761292\n",
            "Epoch: 676, Train Loss: 0.03407080098986626, Test Loss: 0.13082100450992584\n",
            "Epoch: 677, Train Loss: 0.033484023064374924, Test Loss: 0.1305188685655594\n",
            "Epoch: 678, Train Loss: 0.033070120960474014, Test Loss: 0.13424210250377655\n",
            "Epoch: 679, Train Loss: 0.03342386335134506, Test Loss: 0.13282088935375214\n",
            "Epoch: 680, Train Loss: 0.033135950565338135, Test Loss: 0.1285642385482788\n",
            "Epoch: 681, Train Loss: 0.03335258364677429, Test Loss: 0.12787744402885437\n",
            "Epoch: 682, Train Loss: 0.03303879126906395, Test Loss: 0.13258008658885956\n",
            "Epoch: 683, Train Loss: 0.03347369283437729, Test Loss: 0.13582637906074524\n",
            "Epoch: 684, Train Loss: 0.03335648030042648, Test Loss: 0.13323380053043365\n",
            "Epoch: 685, Train Loss: 0.034044817090034485, Test Loss: 0.1315312385559082\n",
            "Epoch: 686, Train Loss: 0.032652221620082855, Test Loss: 0.13118886947631836\n",
            "Epoch: 687, Train Loss: 0.03328142687678337, Test Loss: 0.1321747899055481\n",
            "Epoch: 688, Train Loss: 0.03374467417597771, Test Loss: 0.13366283476352692\n",
            "Epoch: 689, Train Loss: 0.03299103304743767, Test Loss: 0.13354025781154633\n",
            "Epoch: 690, Train Loss: 0.032883115112781525, Test Loss: 0.128747820854187\n",
            "Epoch: 691, Train Loss: 0.033118538558483124, Test Loss: 0.13192135095596313\n",
            "Epoch: 692, Train Loss: 0.0328487828373909, Test Loss: 0.13052469491958618\n",
            "Epoch: 693, Train Loss: 0.03326718881726265, Test Loss: 0.1325070858001709\n",
            "Epoch: 694, Train Loss: 0.03345974534749985, Test Loss: 0.13081280887126923\n",
            "Epoch: 695, Train Loss: 0.032552920281887054, Test Loss: 0.12625989317893982\n",
            "Epoch: 696, Train Loss: 0.032404184341430664, Test Loss: 0.12937645614147186\n",
            "Epoch: 697, Train Loss: 0.032946184277534485, Test Loss: 0.12991376221179962\n",
            "Epoch: 698, Train Loss: 0.033061426132917404, Test Loss: 0.13415375351905823\n",
            "Epoch: 699, Train Loss: 0.03242044523358345, Test Loss: 0.1308009922504425\n",
            "Epoch: 700, Train Loss: 0.03255437687039375, Test Loss: 0.1321335881948471\n",
            "Epoch: 701, Train Loss: 0.03317152336239815, Test Loss: 0.13203923404216766\n",
            "Epoch: 702, Train Loss: 0.032683875411748886, Test Loss: 0.13128986954689026\n",
            "Epoch: 703, Train Loss: 0.032120656222105026, Test Loss: 0.13051654398441315\n",
            "Epoch: 704, Train Loss: 0.03274473547935486, Test Loss: 0.12832511961460114\n",
            "Epoch: 705, Train Loss: 0.03296168893575668, Test Loss: 0.1315016895532608\n",
            "Epoch: 706, Train Loss: 0.03334501013159752, Test Loss: 0.13303561508655548\n",
            "Epoch: 707, Train Loss: 0.032511141151189804, Test Loss: 0.13269776105880737\n",
            "Epoch: 708, Train Loss: 0.03274277225136757, Test Loss: 0.13164567947387695\n",
            "Epoch: 709, Train Loss: 0.03340693935751915, Test Loss: 0.12991869449615479\n",
            "Epoch: 710, Train Loss: 0.03283659741282463, Test Loss: 0.13032220304012299\n",
            "Epoch: 711, Train Loss: 0.03226863965392113, Test Loss: 0.13092510402202606\n",
            "Epoch: 712, Train Loss: 0.03206389397382736, Test Loss: 0.12993881106376648\n",
            "Epoch: 713, Train Loss: 0.03257998824119568, Test Loss: 0.1320330798625946\n",
            "Epoch: 714, Train Loss: 0.032497745007276535, Test Loss: 0.13016089797019958\n",
            "Epoch: 715, Train Loss: 0.03284335881471634, Test Loss: 0.1305924355983734\n",
            "Epoch: 716, Train Loss: 0.03342590481042862, Test Loss: 0.13096848130226135\n",
            "Epoch: 717, Train Loss: 0.0331278070807457, Test Loss: 0.130743607878685\n",
            "Epoch: 718, Train Loss: 0.03313909098505974, Test Loss: 0.13067595660686493\n",
            "Epoch: 719, Train Loss: 0.03237311169505119, Test Loss: 0.13089345395565033\n",
            "Epoch: 720, Train Loss: 0.033006392419338226, Test Loss: 0.13094192743301392\n",
            "Epoch: 721, Train Loss: 0.0322863794863224, Test Loss: 0.13240326941013336\n",
            "Epoch: 722, Train Loss: 0.03257067874073982, Test Loss: 0.13273565471172333\n",
            "Epoch: 723, Train Loss: 0.0324021652340889, Test Loss: 0.13336408138275146\n",
            "Epoch: 724, Train Loss: 0.03248982131481171, Test Loss: 0.13142918050289154\n",
            "Epoch: 725, Train Loss: 0.032360903918743134, Test Loss: 0.13064581155776978\n",
            "Epoch: 726, Train Loss: 0.03247111290693283, Test Loss: 0.13317404687404633\n",
            "Epoch: 727, Train Loss: 0.032562658190727234, Test Loss: 0.13246992230415344\n",
            "Epoch: 728, Train Loss: 0.032443076372146606, Test Loss: 0.1308448314666748\n",
            "Epoch: 729, Train Loss: 0.031940851360559464, Test Loss: 0.1300186961889267\n",
            "Epoch: 730, Train Loss: 0.032165687531232834, Test Loss: 0.13499325513839722\n",
            "Epoch: 731, Train Loss: 0.03197560831904411, Test Loss: 0.1357840746641159\n",
            "Epoch: 732, Train Loss: 0.032433606684207916, Test Loss: 0.13426098227500916\n",
            "Epoch: 733, Train Loss: 0.03276465833187103, Test Loss: 0.13256555795669556\n",
            "Epoch: 734, Train Loss: 0.03275834396481514, Test Loss: 0.13009190559387207\n",
            "Epoch: 735, Train Loss: 0.03223501518368721, Test Loss: 0.1322757601737976\n",
            "Epoch: 736, Train Loss: 0.03232597932219505, Test Loss: 0.13387441635131836\n",
            "Epoch: 737, Train Loss: 0.03221648186445236, Test Loss: 0.13389936089515686\n",
            "Epoch: 738, Train Loss: 0.03267177939414978, Test Loss: 0.13270790874958038\n",
            "Epoch: 739, Train Loss: 0.032447926700115204, Test Loss: 0.13389214873313904\n",
            "Epoch: 740, Train Loss: 0.03219439089298248, Test Loss: 0.1333848237991333\n",
            "Epoch: 741, Train Loss: 0.032279398292303085, Test Loss: 0.13313578069210052\n",
            "Epoch: 742, Train Loss: 0.03229282423853874, Test Loss: 0.13160379230976105\n",
            "Epoch: 743, Train Loss: 0.03211851045489311, Test Loss: 0.13290682435035706\n",
            "Epoch: 744, Train Loss: 0.031813666224479675, Test Loss: 0.1353757232427597\n",
            "Epoch: 745, Train Loss: 0.03233831003308296, Test Loss: 0.13551050424575806\n",
            "Epoch: 746, Train Loss: 0.03208204358816147, Test Loss: 0.1350400298833847\n",
            "Epoch: 747, Train Loss: 0.032803330570459366, Test Loss: 0.1318160593509674\n",
            "Epoch: 748, Train Loss: 0.03164967522025108, Test Loss: 0.1319390833377838\n",
            "Epoch: 749, Train Loss: 0.031892869621515274, Test Loss: 0.13463450968265533\n",
            "Epoch: 750, Train Loss: 0.03195818513631821, Test Loss: 0.1342441439628601\n",
            "Epoch: 751, Train Loss: 0.03187740594148636, Test Loss: 0.13280156254768372\n",
            "Epoch: 752, Train Loss: 0.032372865825891495, Test Loss: 0.1324721872806549\n",
            "Epoch: 753, Train Loss: 0.03245200961828232, Test Loss: 0.13210101425647736\n",
            "Epoch: 754, Train Loss: 0.03231363371014595, Test Loss: 0.13097605109214783\n",
            "Epoch: 755, Train Loss: 0.031914837658405304, Test Loss: 0.13184776902198792\n",
            "Epoch: 756, Train Loss: 0.0322595089673996, Test Loss: 0.13311336934566498\n",
            "Epoch: 757, Train Loss: 0.03238708898425102, Test Loss: 0.13320258259773254\n",
            "Epoch: 758, Train Loss: 0.03182866424322128, Test Loss: 0.13383644819259644\n",
            "Epoch: 759, Train Loss: 0.0320284478366375, Test Loss: 0.13176491856575012\n",
            "Epoch: 760, Train Loss: 0.031200245022773743, Test Loss: 0.13078519701957703\n",
            "Epoch: 761, Train Loss: 0.03197396919131279, Test Loss: 0.13289062678813934\n",
            "Epoch: 762, Train Loss: 0.031838200986385345, Test Loss: 0.1330908238887787\n",
            "Epoch: 763, Train Loss: 0.03138480335474014, Test Loss: 0.1328100562095642\n",
            "Epoch: 764, Train Loss: 0.03175874426960945, Test Loss: 0.1335526704788208\n",
            "Epoch: 765, Train Loss: 0.03196786344051361, Test Loss: 0.1363564133644104\n",
            "Epoch: 766, Train Loss: 0.030988605692982674, Test Loss: 0.13351380825042725\n",
            "Epoch: 767, Train Loss: 0.03170013055205345, Test Loss: 0.12941254675388336\n",
            "Epoch: 768, Train Loss: 0.03154062107205391, Test Loss: 0.13056105375289917\n",
            "Epoch: 769, Train Loss: 0.03152115270495415, Test Loss: 0.13207706809043884\n",
            "Epoch: 770, Train Loss: 0.03158837929368019, Test Loss: 0.13209694623947144\n",
            "Epoch: 771, Train Loss: 0.03172712028026581, Test Loss: 0.13013190031051636\n",
            "Epoch: 772, Train Loss: 0.03183187544345856, Test Loss: 0.12905113399028778\n",
            "Epoch: 773, Train Loss: 0.03178691864013672, Test Loss: 0.12977583706378937\n",
            "Epoch: 774, Train Loss: 0.031692907214164734, Test Loss: 0.13366836309432983\n",
            "Epoch: 775, Train Loss: 0.031822413206100464, Test Loss: 0.13242614269256592\n",
            "Epoch: 776, Train Loss: 0.03187273070216179, Test Loss: 0.13518571853637695\n",
            "Epoch: 777, Train Loss: 0.03114834986627102, Test Loss: 0.1362069547176361\n",
            "Epoch: 778, Train Loss: 0.03159055486321449, Test Loss: 0.13876448571681976\n",
            "Epoch: 779, Train Loss: 0.03208566829562187, Test Loss: 0.1338449865579605\n",
            "Epoch: 780, Train Loss: 0.03120298497378826, Test Loss: 0.12903733551502228\n",
            "Epoch: 781, Train Loss: 0.03137722238898277, Test Loss: 0.13130813837051392\n",
            "Epoch: 782, Train Loss: 0.03128080442547798, Test Loss: 0.1362609565258026\n",
            "Epoch: 783, Train Loss: 0.03206266462802887, Test Loss: 0.1352314054965973\n",
            "Epoch: 784, Train Loss: 0.0314822793006897, Test Loss: 0.13054855167865753\n",
            "Epoch: 785, Train Loss: 0.031287383288145065, Test Loss: 0.13091474771499634\n",
            "Epoch: 786, Train Loss: 0.031764935702085495, Test Loss: 0.13383494317531586\n",
            "Epoch: 787, Train Loss: 0.031020388007164, Test Loss: 0.13830818235874176\n",
            "Epoch: 788, Train Loss: 0.03089216910302639, Test Loss: 0.13403436541557312\n",
            "Epoch: 789, Train Loss: 0.030899114906787872, Test Loss: 0.13424375653266907\n",
            "Epoch: 790, Train Loss: 0.03142600506544113, Test Loss: 0.1381167322397232\n",
            "Epoch: 791, Train Loss: 0.031343333423137665, Test Loss: 0.1376972198486328\n",
            "Epoch: 792, Train Loss: 0.030995480716228485, Test Loss: 0.13297297060489655\n",
            "Epoch: 793, Train Loss: 0.0308734979480505, Test Loss: 0.13106189668178558\n",
            "Epoch: 794, Train Loss: 0.03134065121412277, Test Loss: 0.13726304471492767\n",
            "Epoch: 795, Train Loss: 0.03121296688914299, Test Loss: 0.1420128494501114\n",
            "Epoch: 796, Train Loss: 0.0314020998775959, Test Loss: 0.1380605250597\n",
            "Epoch: 797, Train Loss: 0.03043494001030922, Test Loss: 0.1314672976732254\n",
            "Epoch: 798, Train Loss: 0.031104348599910736, Test Loss: 0.1346723586320877\n",
            "Epoch: 799, Train Loss: 0.031236575916409492, Test Loss: 0.13658608496189117\n",
            "Epoch: 800, Train Loss: 0.03049911931157112, Test Loss: 0.1355755478143692\n",
            "Epoch: 801, Train Loss: 0.030878785997629166, Test Loss: 0.1339482069015503\n",
            "Epoch: 802, Train Loss: 0.031194308772683144, Test Loss: 0.1342087686061859\n",
            "Epoch: 803, Train Loss: 0.0310065858066082, Test Loss: 0.13390463590621948\n",
            "Epoch: 804, Train Loss: 0.030441628769040108, Test Loss: 0.13283173739910126\n",
            "Epoch: 805, Train Loss: 0.030671369284391403, Test Loss: 0.13189120590686798\n",
            "Epoch: 806, Train Loss: 0.03095359355211258, Test Loss: 0.13272997736930847\n",
            "Epoch: 807, Train Loss: 0.030417244881391525, Test Loss: 0.13532070815563202\n",
            "Epoch: 808, Train Loss: 0.03120284155011177, Test Loss: 0.13717344403266907\n",
            "Epoch: 809, Train Loss: 0.030855078250169754, Test Loss: 0.1337776631116867\n",
            "Epoch: 810, Train Loss: 0.030995218083262444, Test Loss: 0.13337455689907074\n",
            "Epoch: 811, Train Loss: 0.03069443814456463, Test Loss: 0.13657225668430328\n",
            "Epoch: 812, Train Loss: 0.030989166349172592, Test Loss: 0.1390780508518219\n",
            "Epoch: 813, Train Loss: 0.03061932884156704, Test Loss: 0.1394556313753128\n",
            "Epoch: 814, Train Loss: 0.030515311285853386, Test Loss: 0.13806356489658356\n",
            "Epoch: 815, Train Loss: 0.030951643362641335, Test Loss: 0.1389947086572647\n",
            "Epoch: 816, Train Loss: 0.0302871260792017, Test Loss: 0.1356218010187149\n",
            "Epoch: 817, Train Loss: 0.030664995312690735, Test Loss: 0.13888558745384216\n",
            "Epoch: 818, Train Loss: 0.03039887361228466, Test Loss: 0.13990655541419983\n",
            "Epoch: 819, Train Loss: 0.030522728338837624, Test Loss: 0.13758312165737152\n",
            "Epoch: 820, Train Loss: 0.030627058818936348, Test Loss: 0.13999342918395996\n",
            "Epoch: 821, Train Loss: 0.030627118423581123, Test Loss: 0.14070802927017212\n",
            "Epoch: 822, Train Loss: 0.0310150608420372, Test Loss: 0.1379225105047226\n",
            "Epoch: 823, Train Loss: 0.030014261603355408, Test Loss: 0.1369197815656662\n",
            "Epoch: 824, Train Loss: 0.03026300109922886, Test Loss: 0.13832253217697144\n",
            "Epoch: 825, Train Loss: 0.030276304110884666, Test Loss: 0.13938531279563904\n",
            "Epoch: 826, Train Loss: 0.030216652899980545, Test Loss: 0.13865002989768982\n",
            "Epoch: 827, Train Loss: 0.030488496646285057, Test Loss: 0.13658688962459564\n",
            "Epoch: 828, Train Loss: 0.03074171580374241, Test Loss: 0.1371963918209076\n",
            "Epoch: 829, Train Loss: 0.03024226985871792, Test Loss: 0.1375877410173416\n",
            "Epoch: 830, Train Loss: 0.030119996517896652, Test Loss: 0.1384277045726776\n",
            "Epoch: 831, Train Loss: 0.029694870114326477, Test Loss: 0.1371772438287735\n",
            "Epoch: 832, Train Loss: 0.03051057644188404, Test Loss: 0.1356356292963028\n",
            "Epoch: 833, Train Loss: 0.030313722789287567, Test Loss: 0.141073077917099\n",
            "Epoch: 834, Train Loss: 0.030239582061767578, Test Loss: 0.1383732408285141\n",
            "Epoch: 835, Train Loss: 0.02949170023202896, Test Loss: 0.13561353087425232\n",
            "Epoch: 836, Train Loss: 0.02986486256122589, Test Loss: 0.13556614518165588\n",
            "Epoch: 837, Train Loss: 0.029923930764198303, Test Loss: 0.1386161893606186\n",
            "Epoch: 838, Train Loss: 0.03050999902188778, Test Loss: 0.14013437926769257\n",
            "Epoch: 839, Train Loss: 0.03025742620229721, Test Loss: 0.1403256058692932\n",
            "Epoch: 840, Train Loss: 0.02986021153628826, Test Loss: 0.13755512237548828\n",
            "Epoch: 841, Train Loss: 0.030080266296863556, Test Loss: 0.13821645081043243\n",
            "Epoch: 842, Train Loss: 0.030435923486948013, Test Loss: 0.1398966908454895\n",
            "Epoch: 843, Train Loss: 0.030274666845798492, Test Loss: 0.14119234681129456\n",
            "Epoch: 844, Train Loss: 0.029245488345623016, Test Loss: 0.14119309186935425\n",
            "Epoch: 845, Train Loss: 0.030287673696875572, Test Loss: 0.13847044110298157\n",
            "Epoch: 846, Train Loss: 0.030554862692952156, Test Loss: 0.13700319826602936\n",
            "Epoch: 847, Train Loss: 0.030425364151597023, Test Loss: 0.13780292868614197\n",
            "Epoch: 848, Train Loss: 0.02932293713092804, Test Loss: 0.14147835969924927\n",
            "Epoch: 849, Train Loss: 0.02958039753139019, Test Loss: 0.14208455383777618\n",
            "Epoch: 850, Train Loss: 0.029541615396738052, Test Loss: 0.1404401808977127\n",
            "Epoch: 851, Train Loss: 0.030857039615511894, Test Loss: 0.14056064188480377\n",
            "Epoch: 852, Train Loss: 0.03019336611032486, Test Loss: 0.13857078552246094\n",
            "Epoch: 853, Train Loss: 0.029825173318386078, Test Loss: 0.13935309648513794\n",
            "Epoch: 854, Train Loss: 0.03024633787572384, Test Loss: 0.13984815776348114\n",
            "Epoch: 855, Train Loss: 0.029593585059046745, Test Loss: 0.14020927250385284\n",
            "Epoch: 856, Train Loss: 0.029516438022255898, Test Loss: 0.1398736834526062\n",
            "Epoch: 857, Train Loss: 0.02954539842903614, Test Loss: 0.13797703385353088\n",
            "Epoch: 858, Train Loss: 0.02959194779396057, Test Loss: 0.1392449587583542\n",
            "Epoch: 859, Train Loss: 0.029921989887952805, Test Loss: 0.14084550738334656\n",
            "Epoch: 860, Train Loss: 0.030112765729427338, Test Loss: 0.13944695889949799\n",
            "Epoch: 861, Train Loss: 0.029882697388529778, Test Loss: 0.14246417582035065\n",
            "Epoch: 862, Train Loss: 0.02941407635807991, Test Loss: 0.14411702752113342\n",
            "Epoch: 863, Train Loss: 0.030244281515479088, Test Loss: 0.14011545479297638\n",
            "Epoch: 864, Train Loss: 0.029558828100562096, Test Loss: 0.1366291642189026\n",
            "Epoch: 865, Train Loss: 0.0301462784409523, Test Loss: 0.1375439614057541\n",
            "Epoch: 866, Train Loss: 0.029652250930666924, Test Loss: 0.14101766049861908\n",
            "Epoch: 867, Train Loss: 0.02961573749780655, Test Loss: 0.14549878239631653\n",
            "Epoch: 868, Train Loss: 0.029610153287649155, Test Loss: 0.14618505537509918\n",
            "Epoch: 869, Train Loss: 0.02900298498570919, Test Loss: 0.14184802770614624\n",
            "Epoch: 870, Train Loss: 0.029015319421887398, Test Loss: 0.1404472142457962\n",
            "Epoch: 871, Train Loss: 0.029460547491908073, Test Loss: 0.1383752077817917\n",
            "Epoch: 872, Train Loss: 0.029494866728782654, Test Loss: 0.14237920939922333\n",
            "Epoch: 873, Train Loss: 0.02914249151945114, Test Loss: 0.1436290740966797\n",
            "Epoch: 874, Train Loss: 0.029668066650629044, Test Loss: 0.14028650522232056\n",
            "Epoch: 875, Train Loss: 0.02916506677865982, Test Loss: 0.13552871346473694\n",
            "Epoch: 876, Train Loss: 0.02984062023460865, Test Loss: 0.14080685377120972\n",
            "Epoch: 877, Train Loss: 0.028911154717206955, Test Loss: 0.1412324160337448\n",
            "Epoch: 878, Train Loss: 0.029249096289277077, Test Loss: 0.13960914313793182\n",
            "Epoch: 879, Train Loss: 0.02884005568921566, Test Loss: 0.14111357927322388\n",
            "Epoch: 880, Train Loss: 0.02951175533235073, Test Loss: 0.1460474729537964\n",
            "Epoch: 881, Train Loss: 0.028459766879677773, Test Loss: 0.14219911396503448\n",
            "Epoch: 882, Train Loss: 0.02905750833451748, Test Loss: 0.1400560736656189\n",
            "Epoch: 883, Train Loss: 0.028973892331123352, Test Loss: 0.13906477391719818\n",
            "Epoch: 884, Train Loss: 0.02842930145561695, Test Loss: 0.138800248503685\n",
            "Epoch: 885, Train Loss: 0.02817171812057495, Test Loss: 0.1426965594291687\n",
            "Epoch: 886, Train Loss: 0.02845243364572525, Test Loss: 0.14465001225471497\n",
            "Epoch: 887, Train Loss: 0.02866320125758648, Test Loss: 0.13573057949543\n",
            "Epoch: 888, Train Loss: 0.028684891760349274, Test Loss: 0.1396198719739914\n",
            "Epoch: 889, Train Loss: 0.02932494878768921, Test Loss: 0.14691205322742462\n",
            "Epoch: 890, Train Loss: 0.028901368379592896, Test Loss: 0.15124036371707916\n",
            "Epoch: 891, Train Loss: 0.0286405012011528, Test Loss: 0.1475663185119629\n",
            "Epoch: 892, Train Loss: 0.029143985360860825, Test Loss: 0.14433743059635162\n",
            "Epoch: 893, Train Loss: 0.028895478695631027, Test Loss: 0.14684845507144928\n",
            "Epoch: 894, Train Loss: 0.029848001897335052, Test Loss: 0.15334953367710114\n",
            "Epoch: 895, Train Loss: 0.0298442505300045, Test Loss: 0.15294389426708221\n",
            "Epoch: 896, Train Loss: 0.02878418378531933, Test Loss: 0.1482095867395401\n",
            "Epoch: 897, Train Loss: 0.028574146330356598, Test Loss: 0.14251556992530823\n",
            "Epoch: 898, Train Loss: 0.028492992743849754, Test Loss: 0.1453985720872879\n",
            "Epoch: 899, Train Loss: 0.028351617977023125, Test Loss: 0.15066185593605042\n",
            "Epoch: 900, Train Loss: 0.028950853273272514, Test Loss: 0.15458931028842926\n",
            "Epoch: 901, Train Loss: 0.0277135968208313, Test Loss: 0.1471395492553711\n",
            "Epoch: 902, Train Loss: 0.028597010299563408, Test Loss: 0.1488364189863205\n",
            "Epoch: 903, Train Loss: 0.028354667127132416, Test Loss: 0.14769844710826874\n",
            "Epoch: 904, Train Loss: 0.028490951284766197, Test Loss: 0.14857159554958344\n",
            "Epoch: 905, Train Loss: 0.028460346162319183, Test Loss: 0.14450804889202118\n",
            "Epoch: 906, Train Loss: 0.029074572026729584, Test Loss: 0.14663948118686676\n",
            "Epoch: 907, Train Loss: 0.028885461390018463, Test Loss: 0.14737343788146973\n",
            "Epoch: 908, Train Loss: 0.02848699502646923, Test Loss: 0.14903871715068817\n",
            "Epoch: 909, Train Loss: 0.02950543351471424, Test Loss: 0.14507988095283508\n",
            "Epoch: 910, Train Loss: 0.02816472202539444, Test Loss: 0.1490064263343811\n",
            "Epoch: 911, Train Loss: 0.028223155066370964, Test Loss: 0.14835432171821594\n",
            "Epoch: 912, Train Loss: 0.02833658456802368, Test Loss: 0.1509489119052887\n",
            "Epoch: 913, Train Loss: 0.02888515405356884, Test Loss: 0.14774194359779358\n",
            "Epoch: 914, Train Loss: 0.028802307322621346, Test Loss: 0.14528340101242065\n",
            "Epoch: 915, Train Loss: 0.028055422008037567, Test Loss: 0.14723852276802063\n",
            "Epoch: 916, Train Loss: 0.028380636125802994, Test Loss: 0.1507381945848465\n",
            "Epoch: 917, Train Loss: 0.028101375326514244, Test Loss: 0.15027697384357452\n",
            "Epoch: 918, Train Loss: 0.02837296947836876, Test Loss: 0.1502263844013214\n",
            "Epoch: 919, Train Loss: 0.02823909930884838, Test Loss: 0.15095961093902588\n",
            "Epoch: 920, Train Loss: 0.028794994577765465, Test Loss: 0.14854808151721954\n",
            "Epoch: 921, Train Loss: 0.028177842497825623, Test Loss: 0.14518462121486664\n",
            "Epoch: 922, Train Loss: 0.0282491073012352, Test Loss: 0.14648130536079407\n",
            "Epoch: 923, Train Loss: 0.028016896918416023, Test Loss: 0.15014351904392242\n",
            "Epoch: 924, Train Loss: 0.02835674397647381, Test Loss: 0.15221624076366425\n",
            "Epoch: 925, Train Loss: 0.027604062110185623, Test Loss: 0.15013648569583893\n",
            "Epoch: 926, Train Loss: 0.02798929251730442, Test Loss: 0.15045671164989471\n",
            "Epoch: 927, Train Loss: 0.028663789853453636, Test Loss: 0.14858143031597137\n",
            "Epoch: 928, Train Loss: 0.028333812952041626, Test Loss: 0.14854533970355988\n",
            "Epoch: 929, Train Loss: 0.027818921953439713, Test Loss: 0.15066975355148315\n",
            "Epoch: 930, Train Loss: 0.028362222015857697, Test Loss: 0.1467181295156479\n",
            "Epoch: 931, Train Loss: 0.027758164331316948, Test Loss: 0.14436353743076324\n",
            "Epoch: 932, Train Loss: 0.02809709496796131, Test Loss: 0.14772528409957886\n",
            "Epoch: 933, Train Loss: 0.027495622634887695, Test Loss: 0.14905525743961334\n",
            "Epoch: 934, Train Loss: 0.02808826044201851, Test Loss: 0.15163226425647736\n",
            "Epoch: 935, Train Loss: 0.02803938277065754, Test Loss: 0.14777778089046478\n",
            "Epoch: 936, Train Loss: 0.02795208804309368, Test Loss: 0.14463500678539276\n",
            "Epoch: 937, Train Loss: 0.027882687747478485, Test Loss: 0.14633634686470032\n",
            "Epoch: 938, Train Loss: 0.02771206572651863, Test Loss: 0.1478574573993683\n",
            "Epoch: 939, Train Loss: 0.027260590344667435, Test Loss: 0.15107975900173187\n",
            "Epoch: 940, Train Loss: 0.02790757641196251, Test Loss: 0.14877071976661682\n",
            "Epoch: 941, Train Loss: 0.027576731517910957, Test Loss: 0.14781075716018677\n",
            "Epoch: 942, Train Loss: 0.027897335588932037, Test Loss: 0.15144497156143188\n",
            "Epoch: 943, Train Loss: 0.027874983847141266, Test Loss: 0.14702102541923523\n",
            "Epoch: 944, Train Loss: 0.027886327356100082, Test Loss: 0.14671948552131653\n",
            "Epoch: 945, Train Loss: 0.026841603219509125, Test Loss: 0.14989599585533142\n",
            "Epoch: 946, Train Loss: 0.028103191405534744, Test Loss: 0.14901144802570343\n",
            "Epoch: 947, Train Loss: 0.028059136122465134, Test Loss: 0.14932557940483093\n",
            "Epoch: 948, Train Loss: 0.027228044345974922, Test Loss: 0.14469659328460693\n",
            "Epoch: 949, Train Loss: 0.027662675827741623, Test Loss: 0.1443338692188263\n",
            "Epoch: 950, Train Loss: 0.02851489745080471, Test Loss: 0.14853650331497192\n",
            "Epoch: 951, Train Loss: 0.027647288516163826, Test Loss: 0.15509682893753052\n",
            "Epoch: 952, Train Loss: 0.027229685336351395, Test Loss: 0.15149781107902527\n",
            "Epoch: 953, Train Loss: 0.027388589456677437, Test Loss: 0.15190555155277252\n",
            "Epoch: 954, Train Loss: 0.02834518998861313, Test Loss: 0.15661810338497162\n",
            "Epoch: 955, Train Loss: 0.028116915374994278, Test Loss: 0.15180373191833496\n",
            "Epoch: 956, Train Loss: 0.02763240598142147, Test Loss: 0.14892902970314026\n",
            "Epoch: 957, Train Loss: 0.02749643474817276, Test Loss: 0.14674800634384155\n",
            "Epoch: 958, Train Loss: 0.02682092972099781, Test Loss: 0.14543326199054718\n",
            "Epoch: 959, Train Loss: 0.02671002969145775, Test Loss: 0.1450943499803543\n",
            "Epoch: 960, Train Loss: 0.027365926653146744, Test Loss: 0.14559942483901978\n",
            "Epoch: 961, Train Loss: 0.026768743991851807, Test Loss: 0.14580370485782623\n",
            "Epoch: 962, Train Loss: 0.028181204572319984, Test Loss: 0.15102392435073853\n",
            "Epoch: 963, Train Loss: 0.027210809290409088, Test Loss: 0.15051837265491486\n",
            "Epoch: 964, Train Loss: 0.02799445018172264, Test Loss: 0.14791427552700043\n",
            "Epoch: 965, Train Loss: 0.027478042989969254, Test Loss: 0.144063800573349\n",
            "Epoch: 966, Train Loss: 0.027447916567325592, Test Loss: 0.14799050986766815\n",
            "Epoch: 967, Train Loss: 0.027079474180936813, Test Loss: 0.15056560933589935\n",
            "Epoch: 968, Train Loss: 0.027026446536183357, Test Loss: 0.14548790454864502\n",
            "Epoch: 969, Train Loss: 0.02705993689596653, Test Loss: 0.14414171874523163\n",
            "Epoch: 970, Train Loss: 0.027919355779886246, Test Loss: 0.14239156246185303\n",
            "Epoch: 971, Train Loss: 0.027970589697360992, Test Loss: 0.1534917652606964\n",
            "Epoch: 972, Train Loss: 0.027670208364725113, Test Loss: 0.15053066611289978\n",
            "Epoch: 973, Train Loss: 0.02719891630113125, Test Loss: 0.14758163690567017\n",
            "Epoch: 974, Train Loss: 0.027791686356067657, Test Loss: 0.14825429022312164\n",
            "Epoch: 975, Train Loss: 0.026499437168240547, Test Loss: 0.1535133719444275\n",
            "Epoch: 976, Train Loss: 0.0270896814763546, Test Loss: 0.1512608528137207\n",
            "Epoch: 977, Train Loss: 0.02705783024430275, Test Loss: 0.1482900232076645\n",
            "Epoch: 978, Train Loss: 0.026865461841225624, Test Loss: 0.15033943951129913\n",
            "Epoch: 979, Train Loss: 0.027396652847528458, Test Loss: 0.15511441230773926\n",
            "Epoch: 980, Train Loss: 0.027369197458028793, Test Loss: 0.15901465713977814\n",
            "Epoch: 981, Train Loss: 0.026868443936109543, Test Loss: 0.1514914631843567\n",
            "Epoch: 982, Train Loss: 0.027081884443759918, Test Loss: 0.1499997228384018\n",
            "Epoch: 983, Train Loss: 0.027064653113484383, Test Loss: 0.15228284895420074\n",
            "Epoch: 984, Train Loss: 0.02712784893810749, Test Loss: 0.15978309512138367\n",
            "Epoch: 985, Train Loss: 0.026502059772610664, Test Loss: 0.16051344573497772\n",
            "Epoch: 986, Train Loss: 0.026565853506326675, Test Loss: 0.15251576900482178\n",
            "Epoch: 987, Train Loss: 0.027271753177046776, Test Loss: 0.15139326453208923\n",
            "Epoch: 988, Train Loss: 0.02786298468708992, Test Loss: 0.1556021124124527\n",
            "Epoch: 989, Train Loss: 0.02699364349246025, Test Loss: 0.15954963862895966\n",
            "Epoch: 990, Train Loss: 0.027648797258734703, Test Loss: 0.161948561668396\n",
            "Epoch: 991, Train Loss: 0.026960767805576324, Test Loss: 0.1565212458372116\n",
            "Epoch: 992, Train Loss: 0.02817699685692787, Test Loss: 0.15238717198371887\n",
            "Epoch: 993, Train Loss: 0.027418609708547592, Test Loss: 0.15076875686645508\n",
            "Epoch: 994, Train Loss: 0.027049990370869637, Test Loss: 0.15365101397037506\n",
            "Epoch: 995, Train Loss: 0.027097512036561966, Test Loss: 0.15167415142059326\n",
            "Epoch: 996, Train Loss: 0.02739931270480156, Test Loss: 0.14997902512550354\n",
            "Epoch: 997, Train Loss: 0.02709195762872696, Test Loss: 0.15141882002353668\n",
            "Epoch: 998, Train Loss: 0.027278874069452286, Test Loss: 0.1573908030986786\n",
            "Epoch: 999, Train Loss: 0.026353569701313972, Test Loss: 0.15442529320716858\n",
            "Epoch: 1000, Train Loss: 0.027259372174739838, Test Loss: 0.1507968306541443\n",
            "Epoch: 1001, Train Loss: 0.02699216827750206, Test Loss: 0.14583604037761688\n",
            "Epoch: 1002, Train Loss: 0.02715831622481346, Test Loss: 0.14468896389007568\n",
            "Epoch: 1003, Train Loss: 0.026751767843961716, Test Loss: 0.15487678349018097\n",
            "Epoch: 1004, Train Loss: 0.026376798748970032, Test Loss: 0.15644314885139465\n",
            "Epoch: 1005, Train Loss: 0.026919538155198097, Test Loss: 0.153322234749794\n",
            "Epoch: 1006, Train Loss: 0.0266546830534935, Test Loss: 0.1472584456205368\n",
            "Epoch: 1007, Train Loss: 0.025861242786049843, Test Loss: 0.1460258811712265\n",
            "Epoch: 1008, Train Loss: 0.026394102722406387, Test Loss: 0.14834065735340118\n",
            "Epoch: 1009, Train Loss: 0.026341598480939865, Test Loss: 0.15535804629325867\n",
            "Epoch: 1010, Train Loss: 0.027259422466158867, Test Loss: 0.15544253587722778\n",
            "Epoch: 1011, Train Loss: 0.02725168876349926, Test Loss: 0.15423524379730225\n",
            "Epoch: 1012, Train Loss: 0.02628956362605095, Test Loss: 0.1486826241016388\n",
            "Epoch: 1013, Train Loss: 0.026943568140268326, Test Loss: 0.15019844472408295\n",
            "Epoch: 1014, Train Loss: 0.026191245764493942, Test Loss: 0.15334108471870422\n",
            "Epoch: 1015, Train Loss: 0.026929162442684174, Test Loss: 0.15404485166072845\n",
            "Epoch: 1016, Train Loss: 0.026358453556895256, Test Loss: 0.15515859425067902\n",
            "Epoch: 1017, Train Loss: 0.026711706072092056, Test Loss: 0.15564440190792084\n",
            "Epoch: 1018, Train Loss: 0.02679990790784359, Test Loss: 0.1501200646162033\n",
            "Epoch: 1019, Train Loss: 0.027077944949269295, Test Loss: 0.1479521095752716\n",
            "Epoch: 1020, Train Loss: 0.027268987149000168, Test Loss: 0.1466820389032364\n",
            "Epoch: 1021, Train Loss: 0.026400845497846603, Test Loss: 0.15107880532741547\n",
            "Epoch: 1022, Train Loss: 0.025718102231621742, Test Loss: 0.15483100712299347\n",
            "Epoch: 1023, Train Loss: 0.02638544887304306, Test Loss: 0.1538626253604889\n",
            "Epoch: 1024, Train Loss: 0.026651661843061447, Test Loss: 0.15297895669937134\n",
            "Epoch: 1025, Train Loss: 0.02645755186676979, Test Loss: 0.15029828250408173\n",
            "Epoch: 1026, Train Loss: 0.026213018223643303, Test Loss: 0.151765376329422\n",
            "Epoch: 1027, Train Loss: 0.026233313605189323, Test Loss: 0.15472090244293213\n",
            "Epoch: 1028, Train Loss: 0.026637014001607895, Test Loss: 0.1562238484621048\n",
            "Epoch: 1029, Train Loss: 0.025685753673315048, Test Loss: 0.15543489158153534\n",
            "Epoch: 1030, Train Loss: 0.02610272914171219, Test Loss: 0.15480566024780273\n",
            "Epoch: 1031, Train Loss: 0.026011059060692787, Test Loss: 0.1492675244808197\n",
            "Epoch: 1032, Train Loss: 0.025764307007193565, Test Loss: 0.15016157925128937\n",
            "Epoch: 1033, Train Loss: 0.025195281952619553, Test Loss: 0.15512193739414215\n",
            "Epoch: 1034, Train Loss: 0.02633785270154476, Test Loss: 0.1537940800189972\n",
            "Epoch: 1035, Train Loss: 0.026014776900410652, Test Loss: 0.15422779321670532\n",
            "Epoch: 1036, Train Loss: 0.026806015521287918, Test Loss: 0.15465185046195984\n",
            "Epoch: 1037, Train Loss: 0.02605745568871498, Test Loss: 0.1540960818529129\n",
            "Epoch: 1038, Train Loss: 0.026151524856686592, Test Loss: 0.15601374208927155\n",
            "Epoch: 1039, Train Loss: 0.0259438157081604, Test Loss: 0.15713603794574738\n",
            "Epoch: 1040, Train Loss: 0.024994580075144768, Test Loss: 0.15632592141628265\n",
            "Epoch: 1041, Train Loss: 0.026334848254919052, Test Loss: 0.15516844391822815\n",
            "Epoch: 1042, Train Loss: 0.026289474219083786, Test Loss: 0.15300253033638\n",
            "Epoch: 1043, Train Loss: 0.02641073614358902, Test Loss: 0.15087845921516418\n",
            "Epoch: 1044, Train Loss: 0.027323493734002113, Test Loss: 0.15208753943443298\n",
            "Epoch: 1045, Train Loss: 0.0258849635720253, Test Loss: 0.1569385975599289\n",
            "Epoch: 1046, Train Loss: 0.02636207453906536, Test Loss: 0.15659676492214203\n",
            "Epoch: 1047, Train Loss: 0.025403499603271484, Test Loss: 0.15358194708824158\n",
            "Epoch: 1048, Train Loss: 0.025923563167452812, Test Loss: 0.15153929591178894\n",
            "Epoch: 1049, Train Loss: 0.025458334013819695, Test Loss: 0.15557339787483215\n",
            "Epoch: 1050, Train Loss: 0.025848442688584328, Test Loss: 0.16002242267131805\n",
            "Epoch: 1051, Train Loss: 0.025727685540914536, Test Loss: 0.15874487161636353\n",
            "Epoch: 1052, Train Loss: 0.025358231738209724, Test Loss: 0.1565006971359253\n",
            "Epoch: 1053, Train Loss: 0.02608494833111763, Test Loss: 0.15684564411640167\n",
            "Epoch: 1054, Train Loss: 0.024868736043572426, Test Loss: 0.15627388656139374\n",
            "Epoch: 1055, Train Loss: 0.025886407122015953, Test Loss: 0.15881839394569397\n",
            "Epoch: 1056, Train Loss: 0.02561105228960514, Test Loss: 0.15676763653755188\n",
            "Epoch: 1057, Train Loss: 0.02580566518008709, Test Loss: 0.1545654982328415\n",
            "Epoch: 1058, Train Loss: 0.025262504816055298, Test Loss: 0.1559962034225464\n",
            "Epoch: 1059, Train Loss: 0.02542697638273239, Test Loss: 0.1558459997177124\n",
            "Epoch: 1060, Train Loss: 0.024934196844697, Test Loss: 0.1548999547958374\n",
            "Epoch: 1061, Train Loss: 0.02694457396864891, Test Loss: 0.15690474212169647\n",
            "Epoch: 1062, Train Loss: 0.025696340948343277, Test Loss: 0.15479740500450134\n",
            "Epoch: 1063, Train Loss: 0.02529621496796608, Test Loss: 0.15491202473640442\n",
            "Epoch: 1064, Train Loss: 0.025633133947849274, Test Loss: 0.15548379719257355\n",
            "Epoch: 1065, Train Loss: 0.026140404865145683, Test Loss: 0.15540343523025513\n",
            "Epoch: 1066, Train Loss: 0.02613169327378273, Test Loss: 0.15424513816833496\n",
            "Epoch: 1067, Train Loss: 0.02597639337182045, Test Loss: 0.15172640979290009\n",
            "Epoch: 1068, Train Loss: 0.025557568296790123, Test Loss: 0.1480899453163147\n",
            "Epoch: 1069, Train Loss: 0.02601468376815319, Test Loss: 0.15223078429698944\n",
            "Epoch: 1070, Train Loss: 0.02615680731832981, Test Loss: 0.1581236720085144\n",
            "Epoch: 1071, Train Loss: 0.025205273181200027, Test Loss: 0.15438200533390045\n",
            "Epoch: 1072, Train Loss: 0.025424063205718994, Test Loss: 0.15273521840572357\n",
            "Epoch: 1073, Train Loss: 0.025915512815117836, Test Loss: 0.15366396307945251\n",
            "Epoch: 1074, Train Loss: 0.02583302929997444, Test Loss: 0.16014862060546875\n",
            "Epoch: 1075, Train Loss: 0.02604358084499836, Test Loss: 0.1585608273744583\n",
            "Epoch: 1076, Train Loss: 0.02548324130475521, Test Loss: 0.16082441806793213\n",
            "Epoch: 1077, Train Loss: 0.02599022164940834, Test Loss: 0.1558239459991455\n",
            "Epoch: 1078, Train Loss: 0.02518809773027897, Test Loss: 0.15448911488056183\n",
            "Epoch: 1079, Train Loss: 0.025267455726861954, Test Loss: 0.1564486175775528\n",
            "Epoch: 1080, Train Loss: 0.02584010362625122, Test Loss: 0.15812070667743683\n",
            "Epoch: 1081, Train Loss: 0.025117864832282066, Test Loss: 0.15360791981220245\n",
            "Epoch: 1082, Train Loss: 0.025284625589847565, Test Loss: 0.1528032273054123\n",
            "Epoch: 1083, Train Loss: 0.02608209289610386, Test Loss: 0.15867727994918823\n",
            "Epoch: 1084, Train Loss: 0.025005219504237175, Test Loss: 0.15166905522346497\n",
            "Epoch: 1085, Train Loss: 0.024731265380978584, Test Loss: 0.1554662138223648\n",
            "Epoch: 1086, Train Loss: 0.025524921715259552, Test Loss: 0.15765510499477386\n",
            "Epoch: 1087, Train Loss: 0.025225097313523293, Test Loss: 0.15529562532901764\n",
            "Epoch: 1088, Train Loss: 0.02532869577407837, Test Loss: 0.15523101389408112\n",
            "Epoch: 1089, Train Loss: 0.02463817596435547, Test Loss: 0.1575459986925125\n",
            "Epoch: 1090, Train Loss: 0.02585851214826107, Test Loss: 0.15705762803554535\n",
            "Epoch: 1091, Train Loss: 0.024910863488912582, Test Loss: 0.15486764907836914\n",
            "Epoch: 1092, Train Loss: 0.024828841909766197, Test Loss: 0.1464737355709076\n",
            "Epoch: 1093, Train Loss: 0.025007527321577072, Test Loss: 0.15555572509765625\n",
            "Epoch: 1094, Train Loss: 0.026060661301016808, Test Loss: 0.15723031759262085\n",
            "Epoch: 1095, Train Loss: 0.025057384744286537, Test Loss: 0.15651942789554596\n",
            "Epoch: 1096, Train Loss: 0.02524964138865471, Test Loss: 0.15555094182491302\n",
            "Epoch: 1097, Train Loss: 0.025506462901830673, Test Loss: 0.15397559106349945\n",
            "Epoch: 1098, Train Loss: 0.02487926557660103, Test Loss: 0.15063373744487762\n",
            "Epoch: 1099, Train Loss: 0.02569504827260971, Test Loss: 0.15477073192596436\n",
            "Epoch: 1100, Train Loss: 0.02461647242307663, Test Loss: 0.15908201038837433\n",
            "Epoch: 1101, Train Loss: 0.025250514969229698, Test Loss: 0.1582222282886505\n",
            "Epoch: 1102, Train Loss: 0.025535425171256065, Test Loss: 0.156685009598732\n",
            "Epoch: 1103, Train Loss: 0.025750383734703064, Test Loss: 0.15987153351306915\n",
            "Epoch: 1104, Train Loss: 0.024923643097281456, Test Loss: 0.15659500658512115\n",
            "Epoch: 1105, Train Loss: 0.025292936712503433, Test Loss: 0.15635256469249725\n",
            "Epoch: 1106, Train Loss: 0.02508492022752762, Test Loss: 0.15850910544395447\n",
            "Epoch: 1107, Train Loss: 0.024721484631299973, Test Loss: 0.15746992826461792\n",
            "Epoch: 1108, Train Loss: 0.024556918069720268, Test Loss: 0.15443986654281616\n",
            "Epoch: 1109, Train Loss: 0.025685660541057587, Test Loss: 0.15895864367485046\n",
            "Epoch: 1110, Train Loss: 0.02475002221763134, Test Loss: 0.1561402529478073\n",
            "Epoch: 1111, Train Loss: 0.02529625967144966, Test Loss: 0.15700364112854004\n",
            "Epoch: 1112, Train Loss: 0.0249977745115757, Test Loss: 0.15433910489082336\n",
            "Epoch: 1113, Train Loss: 0.02479678764939308, Test Loss: 0.1538521647453308\n",
            "Epoch: 1114, Train Loss: 0.025020483881235123, Test Loss: 0.1520504206418991\n",
            "Epoch: 1115, Train Loss: 0.02515142224729061, Test Loss: 0.14988557994365692\n",
            "Epoch: 1116, Train Loss: 0.024126609787344933, Test Loss: 0.15620660781860352\n",
            "Epoch: 1117, Train Loss: 0.024950018152594566, Test Loss: 0.15362662076950073\n",
            "Epoch: 1118, Train Loss: 0.024649618193507195, Test Loss: 0.15500536561012268\n",
            "Epoch: 1119, Train Loss: 0.024775655940175056, Test Loss: 0.1594330370426178\n",
            "Epoch: 1120, Train Loss: 0.025311561301350594, Test Loss: 0.15496234595775604\n",
            "Epoch: 1121, Train Loss: 0.024737883359193802, Test Loss: 0.15433470904827118\n",
            "Epoch: 1122, Train Loss: 0.024907097220420837, Test Loss: 0.15604521334171295\n",
            "Epoch: 1123, Train Loss: 0.02421286702156067, Test Loss: 0.1599307358264923\n",
            "Epoch: 1124, Train Loss: 0.024341687560081482, Test Loss: 0.16142438352108002\n",
            "Epoch: 1125, Train Loss: 0.02531801350414753, Test Loss: 0.15712060034275055\n",
            "Epoch: 1126, Train Loss: 0.02505464106798172, Test Loss: 0.15758590400218964\n",
            "Epoch: 1127, Train Loss: 0.02491161972284317, Test Loss: 0.15491043031215668\n",
            "Epoch: 1128, Train Loss: 0.024906758219003677, Test Loss: 0.15795429050922394\n",
            "Epoch: 1129, Train Loss: 0.024345843121409416, Test Loss: 0.16499868035316467\n",
            "Epoch: 1130, Train Loss: 0.025219591334462166, Test Loss: 0.16296572983264923\n",
            "Epoch: 1131, Train Loss: 0.023676816374063492, Test Loss: 0.1560177356004715\n",
            "Epoch: 1132, Train Loss: 0.02438218705356121, Test Loss: 0.1546085625886917\n",
            "Epoch: 1133, Train Loss: 0.02515377290546894, Test Loss: 0.15707917511463165\n",
            "Epoch: 1134, Train Loss: 0.024328630417585373, Test Loss: 0.15924999117851257\n",
            "Epoch: 1135, Train Loss: 0.024243928492069244, Test Loss: 0.15814834833145142\n",
            "Epoch: 1136, Train Loss: 0.02430124580860138, Test Loss: 0.15790244936943054\n",
            "Epoch: 1137, Train Loss: 0.025082143023610115, Test Loss: 0.1516856849193573\n",
            "Epoch: 1138, Train Loss: 0.024486877024173737, Test Loss: 0.15597768127918243\n",
            "Epoch: 1139, Train Loss: 0.025041654706001282, Test Loss: 0.16277793049812317\n",
            "Epoch: 1140, Train Loss: 0.025335529819130898, Test Loss: 0.15826690196990967\n",
            "Epoch: 1141, Train Loss: 0.024536531418561935, Test Loss: 0.1575847864151001\n",
            "Epoch: 1142, Train Loss: 0.024573687463998795, Test Loss: 0.15423867106437683\n",
            "Epoch: 1143, Train Loss: 0.024837134405970573, Test Loss: 0.15696988999843597\n",
            "Epoch: 1144, Train Loss: 0.0242882389575243, Test Loss: 0.15873831510543823\n",
            "Epoch: 1145, Train Loss: 0.023883916437625885, Test Loss: 0.16051919758319855\n",
            "Epoch: 1146, Train Loss: 0.023960363119840622, Test Loss: 0.15691867470741272\n",
            "Epoch: 1147, Train Loss: 0.023966429755091667, Test Loss: 0.154540553689003\n",
            "Epoch: 1148, Train Loss: 0.024887222796678543, Test Loss: 0.1553243100643158\n",
            "Epoch: 1149, Train Loss: 0.024372834712266922, Test Loss: 0.15545102953910828\n",
            "Epoch: 1150, Train Loss: 0.024586323648691177, Test Loss: 0.15602359175682068\n",
            "Epoch: 1151, Train Loss: 0.023583127185702324, Test Loss: 0.15766046941280365\n",
            "Epoch: 1152, Train Loss: 0.02382330596446991, Test Loss: 0.15866586565971375\n",
            "Epoch: 1153, Train Loss: 0.02454923652112484, Test Loss: 0.15804298222064972\n",
            "Epoch: 1154, Train Loss: 0.024206601083278656, Test Loss: 0.15721215307712555\n",
            "Epoch: 1155, Train Loss: 0.02462940290570259, Test Loss: 0.1613827496767044\n",
            "Epoch: 1156, Train Loss: 0.024996334686875343, Test Loss: 0.15785428881645203\n",
            "Epoch: 1157, Train Loss: 0.024051012471318245, Test Loss: 0.15800046920776367\n",
            "Epoch: 1158, Train Loss: 0.024817684665322304, Test Loss: 0.15267100930213928\n",
            "Epoch: 1159, Train Loss: 0.02421722747385502, Test Loss: 0.16106122732162476\n",
            "Epoch: 1160, Train Loss: 0.024829594418406487, Test Loss: 0.15520019829273224\n",
            "Epoch: 1161, Train Loss: 0.0245426744222641, Test Loss: 0.1578294336795807\n",
            "Epoch: 1162, Train Loss: 0.023951886221766472, Test Loss: 0.1538054496049881\n",
            "Epoch: 1163, Train Loss: 0.02488476037979126, Test Loss: 0.15674032270908356\n",
            "Epoch: 1164, Train Loss: 0.024814940989017487, Test Loss: 0.16296842694282532\n",
            "Epoch: 1165, Train Loss: 0.02438182570040226, Test Loss: 0.16148968040943146\n",
            "Epoch: 1166, Train Loss: 0.024457497522234917, Test Loss: 0.1551687866449356\n",
            "Epoch: 1167, Train Loss: 0.024271387606859207, Test Loss: 0.15693512558937073\n",
            "Epoch: 1168, Train Loss: 0.024317288771271706, Test Loss: 0.16134491562843323\n",
            "Epoch: 1169, Train Loss: 0.024371109902858734, Test Loss: 0.16402535140514374\n",
            "Epoch: 1170, Train Loss: 0.025182591751217842, Test Loss: 0.16184061765670776\n",
            "Epoch: 1171, Train Loss: 0.024151984602212906, Test Loss: 0.15752267837524414\n",
            "Epoch: 1172, Train Loss: 0.02451717108488083, Test Loss: 0.155549094080925\n",
            "Epoch: 1173, Train Loss: 0.024337327107787132, Test Loss: 0.15308359265327454\n",
            "Epoch: 1174, Train Loss: 0.024383820593357086, Test Loss: 0.1555291712284088\n",
            "Epoch: 1175, Train Loss: 0.02418430708348751, Test Loss: 0.1619223952293396\n",
            "Epoch: 1176, Train Loss: 0.024005573242902756, Test Loss: 0.16058167815208435\n",
            "Epoch: 1177, Train Loss: 0.02478357031941414, Test Loss: 0.15558652579784393\n",
            "Epoch: 1178, Train Loss: 0.024415241554379463, Test Loss: 0.16051656007766724\n",
            "Epoch: 1179, Train Loss: 0.02441607043147087, Test Loss: 0.15872392058372498\n",
            "Epoch: 1180, Train Loss: 0.023810239508748055, Test Loss: 0.15667827427387238\n",
            "Epoch: 1181, Train Loss: 0.02361302450299263, Test Loss: 0.15692782402038574\n",
            "Epoch: 1182, Train Loss: 0.0242084302008152, Test Loss: 0.16027824580669403\n",
            "Epoch: 1183, Train Loss: 0.023974349722266197, Test Loss: 0.15809981524944305\n",
            "Epoch: 1184, Train Loss: 0.02463439665734768, Test Loss: 0.1567912995815277\n",
            "Epoch: 1185, Train Loss: 0.0239491518586874, Test Loss: 0.16097688674926758\n",
            "Epoch: 1186, Train Loss: 0.0243282001465559, Test Loss: 0.15778622031211853\n",
            "Epoch: 1187, Train Loss: 0.023938003927469254, Test Loss: 0.15564224123954773\n",
            "Epoch: 1188, Train Loss: 0.023900318890810013, Test Loss: 0.15987226366996765\n",
            "Epoch: 1189, Train Loss: 0.024263717234134674, Test Loss: 0.16399765014648438\n",
            "Epoch: 1190, Train Loss: 0.024119945243000984, Test Loss: 0.15879744291305542\n",
            "Epoch: 1191, Train Loss: 0.024280263110995293, Test Loss: 0.1581810712814331\n",
            "Epoch: 1192, Train Loss: 0.02368021011352539, Test Loss: 0.1522640585899353\n",
            "Epoch: 1193, Train Loss: 0.023824237287044525, Test Loss: 0.1546124517917633\n",
            "Epoch: 1194, Train Loss: 0.023874802514910698, Test Loss: 0.15895023941993713\n",
            "Epoch: 1195, Train Loss: 0.02320096828043461, Test Loss: 0.15887120366096497\n",
            "Epoch: 1196, Train Loss: 0.023857103660702705, Test Loss: 0.15910398960113525\n",
            "Epoch: 1197, Train Loss: 0.023999515920877457, Test Loss: 0.15134549140930176\n",
            "Epoch: 1198, Train Loss: 0.024183649569749832, Test Loss: 0.1539955586194992\n",
            "Epoch: 1199, Train Loss: 0.02391701377928257, Test Loss: 0.1592271775007248\n",
            "Epoch: 1200, Train Loss: 0.023817406967282295, Test Loss: 0.1602754443883896\n",
            "Epoch: 1201, Train Loss: 0.023309839889407158, Test Loss: 0.1580933779478073\n",
            "Epoch: 1202, Train Loss: 0.023509182035923004, Test Loss: 0.15661528706550598\n",
            "Epoch: 1203, Train Loss: 0.023679394274950027, Test Loss: 0.15656360983848572\n",
            "Epoch: 1204, Train Loss: 0.023610660806298256, Test Loss: 0.15638421475887299\n",
            "Epoch: 1205, Train Loss: 0.02464482933282852, Test Loss: 0.1565886288881302\n",
            "Epoch: 1206, Train Loss: 0.023492246866226196, Test Loss: 0.1570887714624405\n",
            "Epoch: 1207, Train Loss: 0.02401462383568287, Test Loss: 0.1553381383419037\n",
            "Epoch: 1208, Train Loss: 0.024380991235375404, Test Loss: 0.1618771255016327\n",
            "Epoch: 1209, Train Loss: 0.023586923256516457, Test Loss: 0.16338086128234863\n",
            "Epoch: 1210, Train Loss: 0.023934056982398033, Test Loss: 0.16120502352714539\n",
            "Epoch: 1211, Train Loss: 0.023459741845726967, Test Loss: 0.1548299491405487\n",
            "Epoch: 1212, Train Loss: 0.023662520572543144, Test Loss: 0.1587834656238556\n",
            "Epoch: 1213, Train Loss: 0.022940779104828835, Test Loss: 0.16286581754684448\n",
            "Epoch: 1214, Train Loss: 0.023770088329911232, Test Loss: 0.16266675293445587\n",
            "Epoch: 1215, Train Loss: 0.0252018291503191, Test Loss: 0.1588093340396881\n",
            "Epoch: 1216, Train Loss: 0.023446062579751015, Test Loss: 0.15742194652557373\n",
            "Epoch: 1217, Train Loss: 0.024085374549031258, Test Loss: 0.15691928565502167\n",
            "Epoch: 1218, Train Loss: 0.023696746677160263, Test Loss: 0.15924203395843506\n",
            "Epoch: 1219, Train Loss: 0.0239071324467659, Test Loss: 0.15714643895626068\n",
            "Epoch: 1220, Train Loss: 0.023562321439385414, Test Loss: 0.16453909873962402\n",
            "Epoch: 1221, Train Loss: 0.023738853633403778, Test Loss: 0.15822692215442657\n",
            "Epoch: 1222, Train Loss: 0.02339717000722885, Test Loss: 0.1554216593503952\n",
            "Epoch: 1223, Train Loss: 0.023208238184452057, Test Loss: 0.15706463158130646\n",
            "Epoch: 1224, Train Loss: 0.02342505007982254, Test Loss: 0.16053250432014465\n",
            "Epoch: 1225, Train Loss: 0.02425270713865757, Test Loss: 0.16033396124839783\n",
            "Epoch: 1226, Train Loss: 0.02329275943338871, Test Loss: 0.16063687205314636\n",
            "Epoch: 1227, Train Loss: 0.024057939648628235, Test Loss: 0.1559567153453827\n",
            "Epoch: 1228, Train Loss: 0.02273007109761238, Test Loss: 0.1525890976190567\n",
            "Epoch: 1229, Train Loss: 0.024050697684288025, Test Loss: 0.15577635169029236\n",
            "Epoch: 1230, Train Loss: 0.023834602907299995, Test Loss: 0.15418881177902222\n",
            "Epoch: 1231, Train Loss: 0.02409360557794571, Test Loss: 0.15859796106815338\n",
            "Epoch: 1232, Train Loss: 0.02399873174726963, Test Loss: 0.15576621890068054\n",
            "Epoch: 1233, Train Loss: 0.023572508245706558, Test Loss: 0.15554383397102356\n",
            "Epoch: 1234, Train Loss: 0.02310122363269329, Test Loss: 0.1548595130443573\n",
            "Epoch: 1235, Train Loss: 0.023130182176828384, Test Loss: 0.15434090793132782\n",
            "Epoch: 1236, Train Loss: 0.023582061752676964, Test Loss: 0.15434275567531586\n",
            "Epoch: 1237, Train Loss: 0.023047778755426407, Test Loss: 0.15845723450183868\n",
            "Epoch: 1238, Train Loss: 0.02346690557897091, Test Loss: 0.1555534452199936\n",
            "Epoch: 1239, Train Loss: 0.02356623113155365, Test Loss: 0.15634948015213013\n",
            "Epoch: 1240, Train Loss: 0.023183239623904228, Test Loss: 0.15872302651405334\n",
            "Epoch: 1241, Train Loss: 0.024121565744280815, Test Loss: 0.15802404284477234\n",
            "Epoch: 1242, Train Loss: 0.023692112416028976, Test Loss: 0.1605193167924881\n",
            "Epoch: 1243, Train Loss: 0.023899046704173088, Test Loss: 0.15980015695095062\n",
            "Epoch: 1244, Train Loss: 0.023800084367394447, Test Loss: 0.15957535803318024\n",
            "Epoch: 1245, Train Loss: 0.024011459201574326, Test Loss: 0.15734551846981049\n",
            "Epoch: 1246, Train Loss: 0.023038510233163834, Test Loss: 0.15624454617500305\n",
            "Epoch: 1247, Train Loss: 0.024288823828101158, Test Loss: 0.15992265939712524\n",
            "Epoch: 1248, Train Loss: 0.02315763384103775, Test Loss: 0.15925829112529755\n",
            "Epoch: 1249, Train Loss: 0.022415341809391975, Test Loss: 0.15850014984607697\n",
            "Epoch: 1250, Train Loss: 0.023877372965216637, Test Loss: 0.15544281899929047\n",
            "Epoch: 1251, Train Loss: 0.023520005866885185, Test Loss: 0.16273604333400726\n",
            "Epoch: 1252, Train Loss: 0.02337382361292839, Test Loss: 0.1609375923871994\n",
            "Epoch: 1253, Train Loss: 0.02351709082722664, Test Loss: 0.15902552008628845\n",
            "Epoch: 1254, Train Loss: 0.02320701815187931, Test Loss: 0.15884776413440704\n",
            "Epoch: 1255, Train Loss: 0.023958392441272736, Test Loss: 0.1593829095363617\n",
            "Epoch: 1256, Train Loss: 0.022679492831230164, Test Loss: 0.15692618489265442\n",
            "Epoch: 1257, Train Loss: 0.023526879027485847, Test Loss: 0.1587740182876587\n",
            "Epoch: 1258, Train Loss: 0.023540804162621498, Test Loss: 0.15601229667663574\n",
            "Epoch: 1259, Train Loss: 0.022743118926882744, Test Loss: 0.15811261534690857\n",
            "Epoch: 1260, Train Loss: 0.022710923105478287, Test Loss: 0.15130481123924255\n",
            "Epoch: 1261, Train Loss: 0.022712325677275658, Test Loss: 0.15427729487419128\n",
            "Epoch: 1262, Train Loss: 0.02332998998463154, Test Loss: 0.15700584650039673\n",
            "Epoch: 1263, Train Loss: 0.023045744746923447, Test Loss: 0.1591303050518036\n",
            "Epoch: 1264, Train Loss: 0.023157941177487373, Test Loss: 0.16358771920204163\n",
            "Epoch: 1265, Train Loss: 0.022907719016075134, Test Loss: 0.16200272738933563\n",
            "Epoch: 1266, Train Loss: 0.02275286614894867, Test Loss: 0.1632390022277832\n",
            "Epoch: 1267, Train Loss: 0.02331986464560032, Test Loss: 0.1627175658941269\n",
            "Epoch: 1268, Train Loss: 0.02324754185974598, Test Loss: 0.16251415014266968\n",
            "Epoch: 1269, Train Loss: 0.0235916618257761, Test Loss: 0.16225413978099823\n",
            "Epoch: 1270, Train Loss: 0.022959182038903236, Test Loss: 0.15567439794540405\n",
            "Epoch: 1271, Train Loss: 0.023334095254540443, Test Loss: 0.1592959612607956\n",
            "Epoch: 1272, Train Loss: 0.022506216540932655, Test Loss: 0.15951009094715118\n",
            "Epoch: 1273, Train Loss: 0.023940434679389, Test Loss: 0.1578987091779709\n",
            "Epoch: 1274, Train Loss: 0.022476347163319588, Test Loss: 0.15621893107891083\n",
            "Epoch: 1275, Train Loss: 0.02305525168776512, Test Loss: 0.15373478829860687\n",
            "Epoch: 1276, Train Loss: 0.023084333166480064, Test Loss: 0.15640215575695038\n",
            "Epoch: 1277, Train Loss: 0.022156238555908203, Test Loss: 0.15831415355205536\n",
            "Epoch: 1278, Train Loss: 0.02308455854654312, Test Loss: 0.15641604363918304\n",
            "Epoch: 1279, Train Loss: 0.02275240235030651, Test Loss: 0.15435494482517242\n",
            "Epoch: 1280, Train Loss: 0.0238046757876873, Test Loss: 0.15588821470737457\n",
            "Epoch: 1281, Train Loss: 0.022742897272109985, Test Loss: 0.1560911238193512\n",
            "Epoch: 1282, Train Loss: 0.023010699078440666, Test Loss: 0.15654106438159943\n",
            "Epoch: 1283, Train Loss: 0.022704575210809708, Test Loss: 0.15972557663917542\n",
            "Epoch: 1284, Train Loss: 0.02353476919233799, Test Loss: 0.16159677505493164\n",
            "Epoch: 1285, Train Loss: 0.022949092090129852, Test Loss: 0.16157838702201843\n",
            "Epoch: 1286, Train Loss: 0.022864561527967453, Test Loss: 0.1579616516828537\n",
            "Epoch: 1287, Train Loss: 0.022509127855300903, Test Loss: 0.15680314600467682\n",
            "Epoch: 1288, Train Loss: 0.02336016297340393, Test Loss: 0.1576528549194336\n",
            "Epoch: 1289, Train Loss: 0.023039966821670532, Test Loss: 0.15983177721500397\n",
            "Epoch: 1290, Train Loss: 0.0225883387029171, Test Loss: 0.15880052745342255\n",
            "Epoch: 1291, Train Loss: 0.023097101598978043, Test Loss: 0.15689632296562195\n",
            "Epoch: 1292, Train Loss: 0.02268705889582634, Test Loss: 0.15426166355609894\n",
            "Epoch: 1293, Train Loss: 0.02292225882411003, Test Loss: 0.15734481811523438\n",
            "Epoch: 1294, Train Loss: 0.02282969281077385, Test Loss: 0.15874890983104706\n",
            "Epoch: 1295, Train Loss: 0.02252190187573433, Test Loss: 0.15838128328323364\n",
            "Epoch: 1296, Train Loss: 0.02337350882589817, Test Loss: 0.15832453966140747\n",
            "Epoch: 1297, Train Loss: 0.023140573874115944, Test Loss: 0.16020150482654572\n",
            "Epoch: 1298, Train Loss: 0.022865455597639084, Test Loss: 0.15842677652835846\n",
            "Epoch: 1299, Train Loss: 0.02393420599400997, Test Loss: 0.16024816036224365\n",
            "Epoch: 1300, Train Loss: 0.022517437115311623, Test Loss: 0.15696069598197937\n",
            "Epoch: 1301, Train Loss: 0.022847313433885574, Test Loss: 0.1580325961112976\n",
            "Epoch: 1302, Train Loss: 0.02317691408097744, Test Loss: 0.15980885922908783\n",
            "Epoch: 1303, Train Loss: 0.023213699460029602, Test Loss: 0.1581398844718933\n",
            "Epoch: 1304, Train Loss: 0.022664472460746765, Test Loss: 0.15755391120910645\n",
            "Epoch: 1305, Train Loss: 0.022455880418419838, Test Loss: 0.1588500589132309\n",
            "Epoch: 1306, Train Loss: 0.022966422140598297, Test Loss: 0.15729176998138428\n",
            "Epoch: 1307, Train Loss: 0.022445375099778175, Test Loss: 0.15980327129364014\n",
            "Epoch: 1308, Train Loss: 0.02205992117524147, Test Loss: 0.1596881002187729\n",
            "Epoch: 1309, Train Loss: 0.022541824728250504, Test Loss: 0.16034561395645142\n",
            "Epoch: 1310, Train Loss: 0.02284269966185093, Test Loss: 0.16110605001449585\n",
            "Epoch: 1311, Train Loss: 0.022803131490945816, Test Loss: 0.16129647195339203\n",
            "Epoch: 1312, Train Loss: 0.022238025441765785, Test Loss: 0.15610730648040771\n",
            "Epoch: 1313, Train Loss: 0.021997589617967606, Test Loss: 0.15885579586029053\n",
            "Epoch: 1314, Train Loss: 0.02207247167825699, Test Loss: 0.16156548261642456\n",
            "Epoch: 1315, Train Loss: 0.023206867277622223, Test Loss: 0.16119980812072754\n",
            "Epoch: 1316, Train Loss: 0.02247317135334015, Test Loss: 0.15999001264572144\n",
            "Epoch: 1317, Train Loss: 0.023563072085380554, Test Loss: 0.16157351434230804\n",
            "Epoch: 1318, Train Loss: 0.02297387644648552, Test Loss: 0.16124726831912994\n",
            "Epoch: 1319, Train Loss: 0.022776827216148376, Test Loss: 0.15895938873291016\n",
            "Epoch: 1320, Train Loss: 0.02195453643798828, Test Loss: 0.1575545370578766\n",
            "Epoch: 1321, Train Loss: 0.022942954674363136, Test Loss: 0.16187575459480286\n",
            "Epoch: 1322, Train Loss: 0.022474750876426697, Test Loss: 0.15947461128234863\n",
            "Epoch: 1323, Train Loss: 0.023379463702440262, Test Loss: 0.1611453890800476\n",
            "Epoch: 1324, Train Loss: 0.022385841235518456, Test Loss: 0.1604241132736206\n",
            "Epoch: 1325, Train Loss: 0.02206924743950367, Test Loss: 0.15710562467575073\n",
            "Epoch: 1326, Train Loss: 0.022351307794451714, Test Loss: 0.15989303588867188\n",
            "Epoch: 1327, Train Loss: 0.022684797644615173, Test Loss: 0.15600907802581787\n",
            "Epoch: 1328, Train Loss: 0.02272218093276024, Test Loss: 0.15771447122097015\n",
            "Epoch: 1329, Train Loss: 0.022730588912963867, Test Loss: 0.16364888846874237\n",
            "Epoch: 1330, Train Loss: 0.0225356537848711, Test Loss: 0.16254639625549316\n",
            "Epoch: 1331, Train Loss: 0.022296864539384842, Test Loss: 0.16559705138206482\n",
            "Epoch: 1332, Train Loss: 0.022553889080882072, Test Loss: 0.1565011590719223\n",
            "Epoch: 1333, Train Loss: 0.02144707553088665, Test Loss: 0.16255292296409607\n",
            "Epoch: 1334, Train Loss: 0.022581672295928, Test Loss: 0.15856188535690308\n",
            "Epoch: 1335, Train Loss: 0.021830487996339798, Test Loss: 0.15919853746891022\n",
            "Epoch: 1336, Train Loss: 0.023168524727225304, Test Loss: 0.16390042006969452\n",
            "Epoch: 1337, Train Loss: 0.02219189889729023, Test Loss: 0.1558409035205841\n",
            "Epoch: 1338, Train Loss: 0.022521238774061203, Test Loss: 0.15727826952934265\n",
            "Epoch: 1339, Train Loss: 0.022897908464074135, Test Loss: 0.16310544312000275\n",
            "Epoch: 1340, Train Loss: 0.022400597110390663, Test Loss: 0.16451096534729004\n",
            "Epoch: 1341, Train Loss: 0.02253480814397335, Test Loss: 0.15980371832847595\n",
            "Epoch: 1342, Train Loss: 0.02187829092144966, Test Loss: 0.1569622904062271\n",
            "Epoch: 1343, Train Loss: 0.02170906402170658, Test Loss: 0.15767712891101837\n",
            "Epoch: 1344, Train Loss: 0.02202978916466236, Test Loss: 0.15765361487865448\n",
            "Epoch: 1345, Train Loss: 0.021136358380317688, Test Loss: 0.16158096492290497\n",
            "Epoch: 1346, Train Loss: 0.023022281005978584, Test Loss: 0.160244882106781\n",
            "Epoch: 1347, Train Loss: 0.022296614944934845, Test Loss: 0.15810377895832062\n",
            "Epoch: 1348, Train Loss: 0.021870598196983337, Test Loss: 0.15839509665966034\n",
            "Epoch: 1349, Train Loss: 0.021992281079292297, Test Loss: 0.1610340178012848\n",
            "Epoch: 1350, Train Loss: 0.02261834777891636, Test Loss: 0.16192813217639923\n",
            "Epoch: 1351, Train Loss: 0.021722441539168358, Test Loss: 0.15686772763729095\n",
            "Epoch: 1352, Train Loss: 0.02268383279442787, Test Loss: 0.15866097807884216\n",
            "Epoch: 1353, Train Loss: 0.022235367447137833, Test Loss: 0.15584775805473328\n",
            "Epoch: 1354, Train Loss: 0.02217903733253479, Test Loss: 0.1551899015903473\n",
            "Epoch: 1355, Train Loss: 0.022232970222830772, Test Loss: 0.15821419656276703\n",
            "Epoch: 1356, Train Loss: 0.022054145112633705, Test Loss: 0.15808337926864624\n",
            "Epoch: 1357, Train Loss: 0.021978134289383888, Test Loss: 0.15740366280078888\n",
            "Epoch: 1358, Train Loss: 0.022172363474965096, Test Loss: 0.15827414393424988\n",
            "Epoch: 1359, Train Loss: 0.02152077853679657, Test Loss: 0.15762801468372345\n",
            "Epoch: 1360, Train Loss: 0.021701078861951828, Test Loss: 0.1634765863418579\n",
            "Epoch: 1361, Train Loss: 0.02262299880385399, Test Loss: 0.15816111862659454\n",
            "Epoch: 1362, Train Loss: 0.02188069559633732, Test Loss: 0.1594957560300827\n",
            "Epoch: 1363, Train Loss: 0.022240592166781425, Test Loss: 0.1571192741394043\n",
            "Epoch: 1364, Train Loss: 0.0219194944947958, Test Loss: 0.16206952929496765\n",
            "Epoch: 1365, Train Loss: 0.02128489501774311, Test Loss: 0.16009759902954102\n",
            "Epoch: 1366, Train Loss: 0.022021040320396423, Test Loss: 0.1551145762205124\n",
            "Epoch: 1367, Train Loss: 0.022947072982788086, Test Loss: 0.15744571387767792\n",
            "Epoch: 1368, Train Loss: 0.022547272965312004, Test Loss: 0.15893486142158508\n",
            "Epoch: 1369, Train Loss: 0.022198785096406937, Test Loss: 0.15997445583343506\n",
            "Epoch: 1370, Train Loss: 0.021939484402537346, Test Loss: 0.15740522742271423\n",
            "Epoch: 1371, Train Loss: 0.022733228281140327, Test Loss: 0.15677592158317566\n",
            "Epoch: 1372, Train Loss: 0.022930612787604332, Test Loss: 0.16102802753448486\n",
            "Epoch: 1373, Train Loss: 0.02236362174153328, Test Loss: 0.16309423744678497\n",
            "Epoch: 1374, Train Loss: 0.021770453080534935, Test Loss: 0.1584865152835846\n",
            "Epoch: 1375, Train Loss: 0.022765440866351128, Test Loss: 0.15508973598480225\n",
            "Epoch: 1376, Train Loss: 0.022061917930841446, Test Loss: 0.15750040113925934\n",
            "Epoch: 1377, Train Loss: 0.022338729351758957, Test Loss: 0.16366852819919586\n",
            "Epoch: 1378, Train Loss: 0.021077949553728104, Test Loss: 0.16056904196739197\n",
            "Epoch: 1379, Train Loss: 0.021772954612970352, Test Loss: 0.15753979980945587\n",
            "Epoch: 1380, Train Loss: 0.022307666018605232, Test Loss: 0.15363219380378723\n",
            "Epoch: 1381, Train Loss: 0.02225160412490368, Test Loss: 0.1589212417602539\n",
            "Epoch: 1382, Train Loss: 0.021728359162807465, Test Loss: 0.16096064448356628\n",
            "Epoch: 1383, Train Loss: 0.02167103812098503, Test Loss: 0.15888424217700958\n",
            "Epoch: 1384, Train Loss: 0.022315142676234245, Test Loss: 0.1566821187734604\n",
            "Epoch: 1385, Train Loss: 0.022059539332985878, Test Loss: 0.153013676404953\n",
            "Epoch: 1386, Train Loss: 0.021197479218244553, Test Loss: 0.16010889410972595\n",
            "Epoch: 1387, Train Loss: 0.02165983058512211, Test Loss: 0.15888403356075287\n",
            "Epoch: 1388, Train Loss: 0.022703194990754128, Test Loss: 0.15628497302532196\n",
            "Epoch: 1389, Train Loss: 0.022240474820137024, Test Loss: 0.15703266859054565\n",
            "Epoch: 1390, Train Loss: 0.022224023938179016, Test Loss: 0.15539395809173584\n",
            "Epoch: 1391, Train Loss: 0.021859969943761826, Test Loss: 0.15621818602085114\n",
            "Epoch: 1392, Train Loss: 0.02154644764959812, Test Loss: 0.16279886662960052\n",
            "Epoch: 1393, Train Loss: 0.021367767825722694, Test Loss: 0.16389501094818115\n",
            "Epoch: 1394, Train Loss: 0.022662071511149406, Test Loss: 0.15983787178993225\n",
            "Epoch: 1395, Train Loss: 0.022212935611605644, Test Loss: 0.15480411052703857\n",
            "Epoch: 1396, Train Loss: 0.021876849234104156, Test Loss: 0.15393897891044617\n",
            "Epoch: 1397, Train Loss: 0.02198985405266285, Test Loss: 0.1592240333557129\n",
            "Epoch: 1398, Train Loss: 0.02194833755493164, Test Loss: 0.1622202843427658\n",
            "Epoch: 1399, Train Loss: 0.02089809440076351, Test Loss: 0.1601547747850418\n",
            "Epoch: 1400, Train Loss: 0.022304773330688477, Test Loss: 0.15849173069000244\n",
            "Epoch: 1401, Train Loss: 0.022000515833497047, Test Loss: 0.15884515643119812\n",
            "Epoch: 1402, Train Loss: 0.02240612916648388, Test Loss: 0.157736137509346\n",
            "Epoch: 1403, Train Loss: 0.02108045667409897, Test Loss: 0.15874414145946503\n",
            "Epoch: 1404, Train Loss: 0.0213180985301733, Test Loss: 0.1552390605211258\n",
            "Epoch: 1405, Train Loss: 0.022034144029021263, Test Loss: 0.1567138433456421\n",
            "Epoch: 1406, Train Loss: 0.022462204098701477, Test Loss: 0.1600012630224228\n",
            "Epoch: 1407, Train Loss: 0.021256757900118828, Test Loss: 0.16194093227386475\n",
            "Epoch: 1408, Train Loss: 0.02176368236541748, Test Loss: 0.1558891087770462\n",
            "Epoch: 1409, Train Loss: 0.02124849148094654, Test Loss: 0.15903021395206451\n",
            "Epoch: 1410, Train Loss: 0.022085268050432205, Test Loss: 0.15809275209903717\n",
            "Epoch: 1411, Train Loss: 0.02192852646112442, Test Loss: 0.15647955238819122\n",
            "Epoch: 1412, Train Loss: 0.02253601886332035, Test Loss: 0.15938962996006012\n",
            "Epoch: 1413, Train Loss: 0.021433576941490173, Test Loss: 0.15552589297294617\n",
            "Epoch: 1414, Train Loss: 0.02150450460612774, Test Loss: 0.15525303781032562\n",
            "Epoch: 1415, Train Loss: 0.021915797144174576, Test Loss: 0.15798687934875488\n",
            "Epoch: 1416, Train Loss: 0.02149682119488716, Test Loss: 0.15485744178295135\n",
            "Epoch: 1417, Train Loss: 0.021898178383708, Test Loss: 0.15794652700424194\n",
            "Epoch: 1418, Train Loss: 0.02135966718196869, Test Loss: 0.15737947821617126\n",
            "Epoch: 1419, Train Loss: 0.022083871066570282, Test Loss: 0.1601058542728424\n",
            "Epoch: 1420, Train Loss: 0.022405210882425308, Test Loss: 0.1580660492181778\n",
            "Epoch: 1421, Train Loss: 0.021029846742749214, Test Loss: 0.15646255016326904\n",
            "Epoch: 1422, Train Loss: 0.021185360848903656, Test Loss: 0.15296518802642822\n",
            "Epoch: 1423, Train Loss: 0.021449081599712372, Test Loss: 0.15048566460609436\n",
            "Epoch: 1424, Train Loss: 0.021695168688893318, Test Loss: 0.1558152288198471\n",
            "Epoch: 1425, Train Loss: 0.02120116911828518, Test Loss: 0.15970659255981445\n",
            "Epoch: 1426, Train Loss: 0.02155783586204052, Test Loss: 0.15696661174297333\n",
            "Epoch: 1427, Train Loss: 0.022378718480467796, Test Loss: 0.15524286031723022\n",
            "Epoch: 1428, Train Loss: 0.022304734215140343, Test Loss: 0.15414351224899292\n",
            "Epoch: 1429, Train Loss: 0.021907290443778038, Test Loss: 0.1572582721710205\n",
            "Epoch: 1430, Train Loss: 0.021847760304808617, Test Loss: 0.16197064518928528\n",
            "Epoch: 1431, Train Loss: 0.02205401286482811, Test Loss: 0.15808872878551483\n",
            "Epoch: 1432, Train Loss: 0.021781301125884056, Test Loss: 0.15590928494930267\n",
            "Epoch: 1433, Train Loss: 0.021607039496302605, Test Loss: 0.154741570353508\n",
            "Epoch: 1434, Train Loss: 0.021301664412021637, Test Loss: 0.15635555982589722\n",
            "Epoch: 1435, Train Loss: 0.021753383800387383, Test Loss: 0.15573175251483917\n",
            "Epoch: 1436, Train Loss: 0.021938204765319824, Test Loss: 0.1547507494688034\n",
            "Epoch: 1437, Train Loss: 0.021461784839630127, Test Loss: 0.15252619981765747\n",
            "Epoch: 1438, Train Loss: 0.021361973136663437, Test Loss: 0.15922868251800537\n",
            "Epoch: 1439, Train Loss: 0.021018648520112038, Test Loss: 0.16279000043869019\n",
            "Epoch: 1440, Train Loss: 0.021271036937832832, Test Loss: 0.16215842962265015\n",
            "Epoch: 1441, Train Loss: 0.021120917052030563, Test Loss: 0.16073665022850037\n",
            "Epoch: 1442, Train Loss: 0.021591566503047943, Test Loss: 0.15574400126934052\n",
            "Epoch: 1443, Train Loss: 0.02171306312084198, Test Loss: 0.1581379622220993\n",
            "Epoch: 1444, Train Loss: 0.022050080820918083, Test Loss: 0.1591661125421524\n",
            "Epoch: 1445, Train Loss: 0.02139963023364544, Test Loss: 0.16059044003486633\n",
            "Epoch: 1446, Train Loss: 0.021222734823822975, Test Loss: 0.1642555296421051\n",
            "Epoch: 1447, Train Loss: 0.021158277988433838, Test Loss: 0.15720702707767487\n",
            "Epoch: 1448, Train Loss: 0.021300850436091423, Test Loss: 0.15703266859054565\n",
            "Epoch: 1449, Train Loss: 0.021547440439462662, Test Loss: 0.15856477618217468\n",
            "Epoch: 1450, Train Loss: 0.02153657376766205, Test Loss: 0.15892796218395233\n",
            "Epoch: 1451, Train Loss: 0.02140919305384159, Test Loss: 0.16066880524158478\n",
            "Epoch: 1452, Train Loss: 0.021087486296892166, Test Loss: 0.1607200801372528\n",
            "Epoch: 1453, Train Loss: 0.02101779356598854, Test Loss: 0.16476264595985413\n",
            "Epoch: 1454, Train Loss: 0.020883256569504738, Test Loss: 0.1601187139749527\n",
            "Epoch: 1455, Train Loss: 0.021077265962958336, Test Loss: 0.15847249329090118\n",
            "Epoch: 1456, Train Loss: 0.021363917738199234, Test Loss: 0.16522154211997986\n",
            "Epoch: 1457, Train Loss: 0.021144405007362366, Test Loss: 0.16067032516002655\n",
            "Epoch: 1458, Train Loss: 0.02143668569624424, Test Loss: 0.16712352633476257\n",
            "Epoch: 1459, Train Loss: 0.021002892404794693, Test Loss: 0.1588968187570572\n",
            "Epoch: 1460, Train Loss: 0.02078920230269432, Test Loss: 0.1560383141040802\n",
            "Epoch: 1461, Train Loss: 0.02090843766927719, Test Loss: 0.15984828770160675\n",
            "Epoch: 1462, Train Loss: 0.02136840857565403, Test Loss: 0.16173884272575378\n",
            "Epoch: 1463, Train Loss: 0.02097192034125328, Test Loss: 0.15843655169010162\n",
            "Epoch: 1464, Train Loss: 0.02090604230761528, Test Loss: 0.15582238137722015\n",
            "Epoch: 1465, Train Loss: 0.020462224259972572, Test Loss: 0.15603432059288025\n",
            "Epoch: 1466, Train Loss: 0.021200021728873253, Test Loss: 0.15716464817523956\n",
            "Epoch: 1467, Train Loss: 0.021356914192438126, Test Loss: 0.15658576786518097\n",
            "Epoch: 1468, Train Loss: 0.021570304408669472, Test Loss: 0.1577521413564682\n",
            "Epoch: 1469, Train Loss: 0.021565435454249382, Test Loss: 0.1545657068490982\n",
            "Epoch: 1470, Train Loss: 0.021268170326948166, Test Loss: 0.15676772594451904\n",
            "Epoch: 1471, Train Loss: 0.02118295431137085, Test Loss: 0.1637418568134308\n",
            "Epoch: 1472, Train Loss: 0.020797371864318848, Test Loss: 0.1584283411502838\n",
            "Epoch: 1473, Train Loss: 0.020959071815013885, Test Loss: 0.1570471227169037\n",
            "Epoch: 1474, Train Loss: 0.021355174481868744, Test Loss: 0.1599983125925064\n",
            "Epoch: 1475, Train Loss: 0.021005181595683098, Test Loss: 0.15737147629261017\n",
            "Epoch: 1476, Train Loss: 0.02068188041448593, Test Loss: 0.15932506322860718\n",
            "Epoch: 1477, Train Loss: 0.021376412361860275, Test Loss: 0.15773366391658783\n",
            "Epoch: 1478, Train Loss: 0.021363887935876846, Test Loss: 0.15506111085414886\n",
            "Epoch: 1479, Train Loss: 0.021927589550614357, Test Loss: 0.1530056744813919\n",
            "Epoch: 1480, Train Loss: 0.021102532744407654, Test Loss: 0.15967006981372833\n",
            "Epoch: 1481, Train Loss: 0.021278293803334236, Test Loss: 0.16069835424423218\n",
            "Epoch: 1482, Train Loss: 0.020475415512919426, Test Loss: 0.1602608561515808\n",
            "Epoch: 1483, Train Loss: 0.02137545496225357, Test Loss: 0.15698502957820892\n",
            "Epoch: 1484, Train Loss: 0.021560702472925186, Test Loss: 0.15584424138069153\n",
            "Epoch: 1485, Train Loss: 0.02009730599820614, Test Loss: 0.15930061042308807\n",
            "Epoch: 1486, Train Loss: 0.021346591413021088, Test Loss: 0.16120673716068268\n",
            "Epoch: 1487, Train Loss: 0.021273324266076088, Test Loss: 0.15512487292289734\n",
            "Epoch: 1488, Train Loss: 0.020305726677179337, Test Loss: 0.15628531575202942\n",
            "Epoch: 1489, Train Loss: 0.020717868581414223, Test Loss: 0.16166885197162628\n",
            "Epoch: 1490, Train Loss: 0.020763155072927475, Test Loss: 0.1613500416278839\n",
            "Epoch: 1491, Train Loss: 0.02124541439116001, Test Loss: 0.15740548074245453\n",
            "Epoch: 1492, Train Loss: 0.021031778305768967, Test Loss: 0.1587812900543213\n",
            "Epoch: 1493, Train Loss: 0.020899727940559387, Test Loss: 0.16435201466083527\n",
            "Epoch: 1494, Train Loss: 0.020545918494462967, Test Loss: 0.16094443202018738\n",
            "Epoch: 1495, Train Loss: 0.020426873117685318, Test Loss: 0.16012999415397644\n",
            "Epoch: 1496, Train Loss: 0.02093951217830181, Test Loss: 0.1577395647764206\n",
            "Epoch: 1497, Train Loss: 0.02060365118086338, Test Loss: 0.15629221498966217\n",
            "Epoch: 1498, Train Loss: 0.02072587050497532, Test Loss: 0.15816424787044525\n",
            "Epoch: 1499, Train Loss: 0.021751314401626587, Test Loss: 0.1620524823665619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIkSNU3O1FM4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "473b9814-b2f8-4110-8aea-079470be9c35"
      },
      "source": [
        "plt.plot(train_losses, label=\"train\")\n",
        "plt.plot(test_losses, label = \"test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2c64cca9e8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsUvgqj9FBtI"
      },
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model(X_test)\n",
        "  y_pred = y_pred.cpu()\n",
        "  y_pred = scY.inverse_transform(y_pred)\n",
        "  y_test = y_test.cpu()\n",
        "  y_test = scY.inverse_transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOqrX4bXHLOI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9c0d8fc1-a552-4b9a-f141-5de46b190382"
      },
      "source": [
        "plt.plot(y_pred, label=\"pred\")\n",
        "plt.plot(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2c64c3ba20>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBCsicGHVdm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a9b42cd0-5124-43f5-b3e1-6b1ab93e9ac2"
      },
      "source": [
        "y_test \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.67400005],\n",
              "       [1.42700003],\n",
              "       [1.45599999],\n",
              "       ...,\n",
              "       [1.68700001],\n",
              "       [1.68499995],\n",
              "       [1.14499998]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3o57IYjWq30"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qoWbIU0W9_O"
      },
      "source": [
        "y_pred = y_pred  > 25\n",
        "#y_pred = y_pred.astype(int)\n",
        "\n",
        "y_test = y_test  > 25\n",
        "#y_test = y_test.astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYCOITynX22t"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm_rnn_test = confusion_matrix( y_pred,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0pxVZjAX8ok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9a9e8bc2-ee45-4c18-cc8c-f0649ab6701e"
      },
      "source": [
        "cm_rnn_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[760, 110],\n",
              "       [189, 381]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXzStGEMX-dX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "866fdee2-0e36-489b-90e2-498808ec47d9"
      },
      "source": [
        "plt.plot(validation_predictions, label=\"pred\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe3de367ac8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7f58ZELdEq2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b40714a2-baf7-41cd-c3b1-aaceff498c81"
      },
      "source": [
        "validation_predictions.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veYVW_YqF8C_"
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF4TJRLLGW-n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ead6e6b2-ffe2-401b-a8c1-cd3e6330fb80"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhatVMfA1mdI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zURg2DsK1vSD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}